{"id":"quarry-05t","title":"Rename GitHub repo from quarry-mcp to quarry","description":"DESIGN-GUIDANCE.md requires repo names to match the CLI command name without a -mcp suffix. The repo is currently jmf-pobox/quarry-mcp and should be quarry. Coordinate with the PyPI rename (quarry-wul). Update all references: install scripts, README, PROJECTS.md, .mcpb manifest, Quarry Menu Bar's upstream URL.","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-17T09:40:39.412479-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-19T17:22:45.424934-08:00","closed_at":"2026-02-19T17:22:45.424934-08:00","close_reason":"GitHub repo renamed from jmf-pobox/quarry-mcp to punt-labs/quarry. Org transfer + rename completed."}
{"id":"quarry-0kc","title":"feat: ResultRow + ResultDetail views with copy and reveal actions","status":"closed","priority":1,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-13T17:03:52.477362-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-13T18:08:16.244287-08:00","closed_at":"2026-02-13T18:08:16.244287-08:00","close_reason":"Closed","dependencies":[{"issue_id":"quarry-0kc","depends_on_id":"quarry-4f4","type":"blocks","created_at":"2026-02-13T17:03:59.641084-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-0ue","title":"feature: named databases with --db flag","description":"Replace LANCEDB_PATH env var juggling with a simple --db flag for named databases.\n\n## Design\n- `quarry ingest report.pdf --db work` resolves to `~/.quarry/data/work/lancedb`\n- `quarry search \"revenue\" --db work`\n- `quarry mcp --db work` starts MCP server against that database\n- No flag defaults to `~/.quarry/data/default/lancedb`\n- `quarry databases` lists named databases with stats (doc count, size)\n- LANCEDB_PATH env var still works as an override for edge cases\n\n## Mental model\n- Database (--db): hard separation, separate MCP instances (work vs personal)\n- Collection (--collection): logical grouping within a database (folders in a cabinet)\n\n## Implementation\n- Add --db option to all CLI commands and mcp subcommand\n- Resolver: settings.quarry_root / db_name / \"lancedb\"\n- Update README Multiple Indices section with simpler examples\n- Update quarry install to use default database path convention\n- No migration needed — no production users yet","status":"closed","priority":2,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-13T06:45:10.729727-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-13T06:58:38.420585-08:00","closed_at":"2026-02-13T06:58:38.420585-08:00","close_reason":"Closed"}
{"id":"quarry-1fi","title":"tool: Epic 6 — Multi-index management","description":"First-class support for organizing documents into collections.\n\n- Named indices with isolated storage\n- Per-index configuration (embedding model, chunk size)\n- Cross-index search\n- Index metadata and statistics","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T09:19:18.015614-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.002039-08:00","closed_at":"2026-02-08T18:45:07.315467-08:00","close_reason":"Epic 6 complete: collections support across model, database, pipeline, MCP, and CLI. 8 commits, 198 tests."}
{"id":"quarry-1i4","title":"feat: empty and error state views for all states","status":"closed","priority":1,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-13T17:03:53.852963-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-13T18:11:11.453308-08:00","closed_at":"2026-02-13T18:11:11.453308-08:00","close_reason":"Closed","dependencies":[{"issue_id":"quarry-1i4","depends_on_id":"quarry-0kc","type":"blocks","created_at":"2026-02-13T17:03:59.859257-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-1ke","title":"transform: Local OCR backend (RapidOCR)","description":"Make the OCR backend pluggable so quarry can run without AWS credentials.\n\n## Motivation\n- Eliminates AWS dependency and per-page cost ($1.50/1000 pages)\n- Enables offline use\n- Simpler setup (no IAM, S3 bucket, or credentials needed)\n\n## Approach\n- Define an OcrBackend protocol with two operations: sync single-page OCR and async multi-page OCR\n- Implement TextractBackend (existing code in ocr_client.py)\n- Implement LocalBackend wrapping a local engine (PaddleOCR, EasyOCR, or Tesseract)\n- Add OCR_BACKEND setting (default: \"textract\", alternative: \"local\")\n- Pipeline calls backend through protocol, no other changes needed\n\n## Candidates\n- PaddleOCR: best accuracy, ~100MB models, CPU or GPU\n- EasyOCR: good accuracy, PyTorch-based, ~200MB models\n- Tesseract: simplest install, weakest accuracy on noisy/skewed scans\n\n## Open Questions\n- Which local engine? PaddleOCR has best benchmarks but adds PaddlePaddle dependency\n- Should local be an optional extra (quarry-mcp[local])?\n- Acceptable accuracy threshold for handwritten/skewed documents?","status":"closed","priority":0,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-09T05:00:53.494075-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T18:50:10.243054-08:00","closed_at":"2026-02-11T18:50:10.243054-08:00","close_reason":"Implemented LocalOcrBackend using RapidOCR (pure Python, ONNX Runtime). Default changed from textract to local. 6 commits on feat/local-ocr branch."}
{"id":"quarry-1t1","title":"Investigate complexity hotspots and consider lowering mccabe threshold","description":"Two functions at complexity 10 (_chunk_embed_store, sync_collection), two at 9 (ingest_document, _bulk_ingest_entries). Current ruff threshold is default 10 — nothing fails but we're at the ceiling. Investigate whether these can be simplified and whether lowering to 8 is feasible.","status":"open","priority":4,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-24T10:57:49.034273-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-24T10:57:49.034273-08:00"}
{"id":"quarry-2j7","title":"pipeline: Downscale oversized images before OCR","status":"closed","priority":2,"issue_type":"bug","owner":"jmf@pobox.com","created_at":"2026-02-09T16:12:08.456359-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.998916-08:00","closed_at":"2026-02-09T17:16:37.264251-08:00","close_reason":"PR #7 merged: oversized images downscaled before OCR, 13 failures resolved"}
{"id":"quarry-306","title":"Layer 0: auto-index codebase on SessionStart","description":"SessionStart hook that auto-registers the current git repo with quarry and syncs. Outputs additionalContext telling Claude to use /find and search_documents for codebase navigation instead of Grep/Glob exploration. Highest leverage — every session benefits from indexed codebase.","status":"closed","priority":1,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-24T11:05:19.082636-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-24T16:38:36.449312-08:00","closed_at":"2026-02-24T16:38:36.449312-08:00","close_reason":"Closed","dependencies":[{"issue_id":"quarry-306","depends_on_id":"quarry-dpu","type":"blocks","created_at":"2026-02-24T11:05:25.04598-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-3fx","title":"feat: DaemonManager process lifecycle for quarry serve","status":"closed","priority":1,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-13T17:03:50.31168-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-13T18:01:56.77938-08:00","closed_at":"2026-02-13T18:01:56.77938-08:00","close_reason":"Closed","dependencies":[{"issue_id":"quarry-3fx","depends_on_id":"quarry-kou","type":"blocks","created_at":"2026-02-13T17:03:59.094866-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-3gl","title":"Improve quarry install and doctor UX","description":"quarry install and quarry doctor are functional but have UX issues that hurt the first-run experience:\n\n1. Doctor: RapidOCR and botocore dump INFO logs before clean check output\n2. Install: no error handling around model download (raw traceback on failure)\n3. Install: no post-install verification (should run doctor checks after)\n4. Neither shows quarry-mcp version\n5. Doctor: no disk usage info (model size, DB size)\n6. Install: no clear summary of what succeeded vs failed\n\nFix: suppress third-party logging during checks, add try/except around install steps with friendly errors, run doctor after install, add version header, add storage info to doctor.","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-14T17:12:39.249716-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-14T17:40:29.002345-08:00","closed_at":"2026-02-14T17:40:29.002345-08:00","close_reason":"PR #37 merged: install script, doctor UX, MCP checks"}
{"id":"quarry-42y","title":"format: HTML ingestion","description":"Ingest saved HTML files. Strip boilerplate/nav/scripts, extract article content. Library: beautifulsoup4. Straightforward text extraction.","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-09T05:36:29.715704-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-14T09:17:00.559312-08:00","closed_at":"2026-02-14T09:17:00.559312-08:00","close_reason":"PR #33 open, Copilot review pending"}
{"id":"quarry-4d8","title":"Smart /ingest: auto-discover sitemap from any URL","description":"When /ingest receives a URL like https://code.claude.com/docs, auto-discover the site's sitemap before falling back to single-page ingest.\n\nDiscovery steps (in Python, not prompt):\n1. Fetch {origin}/robots.txt — parse Sitemap: directives\n2. If no sitemap in robots.txt, try {origin}/sitemap.xml directly\n3. If sitemap found, call ingest_sitemap with include_patterns from the URL path prefix (e.g. /docs/*)\n4. If no sitemap found, fall back to ingest_url for the single page\n\nImplementation: new MCP tool (e.g. ingest_smart or enhance ingest_url) that wraps the discovery logic in pipeline.py. Update /ingest command to call it for URLs instead of ingest_url directly.","status":"closed","priority":2,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-24T02:16:30.559489-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-24T10:46:12.783327-08:00","closed_at":"2026-02-24T10:46:12.783327-08:00","close_reason":"Merged PR #59: smart /ingest with USP-backed sitemap auto-discovery, directory support, review feedback addressed"}
{"id":"quarry-4f4","title":"feat: SearchPanel + SearchViewModel with debounced search","status":"closed","priority":1,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-13T17:03:51.659784-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-13T18:07:01.062596-08:00","closed_at":"2026-02-13T18:07:01.062596-08:00","close_reason":"Closed","dependencies":[{"issue_id":"quarry-4f4","depends_on_id":"quarry-ee1","type":"blocks","created_at":"2026-02-13T17:03:59.422806-08:00","created_by":"\"jmf-pobox\""},{"issue_id":"quarry-4f4","depends_on_id":"quarry-wzu","type":"blocks","created_at":"2026-02-13T17:03:59.531646-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-4ry","title":"pipeline: Fix f-string log formatting","description":"pipeline.py has 11 progress() calls using f-strings that pass through _make_progress() to logger.info(message). This defeats lazy evaluation. Refactor _make_progress to accept format string + args, or convert callers to use %s-style formatting. See NON-FUNCTIONAL-DESIGN.md logging format standard.","status":"closed","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T12:11:59.136548-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.005077-08:00","closed_at":"2026-02-08T12:30:15.66313-08:00","close_reason":"Closed"}
{"id":"quarry-4xq","title":"tool: Hybrid document-level search","description":"Add document-level search combining sparse (keyword) and dense (vector) retrieval to support exhaustive queries like 'how much did I spend on maintenance' where top-N chunk similarity is the wrong tool.\n\n## Problem\n\nCurrent search returns top-N chunks by vector similarity. Works for conceptual queries but fails for exhaustive queries that need ALL matching documents regardless of similarity rank. Document names are unreliable (e.g. scan.pdf, IMG_5349.jpg) so metadata filtering by name is insufficient.\n\n## Design\n\n### Document metadata table\n\nAt ingestion time, after chunking and embedding, generate and store per-document:\n- Document-level embedding: np.mean(chunk_vectors, axis=0) — already computed, just store the mean\n- Keywords: TF-IDF or statistical extraction from page text — zero additional API cost\n- Store in a separate document_metadata table in LanceDB\n\n### New MCP tool: find_documents\n\nHybrid search against the document metadata table:\n- Dense: vector similarity against document-level embedding\n- Sparse: keyword/BM25 matching against extracted terms\n- LanceDB supports both natively (full-text search index + vector index)\n- Returns document-level results (name, collection, pages, keywords) not chunks\n- Small responses — document list only, no chunk text\n\n### Retrieval flow for exhaustive queries\n\n1. find_documents(collection='hallberg-rassy', query='invoice') → complete document list (small response)\n2. get_page(doc, page) for each document → extract specific data\n3. LLM aggregates the answers\n\n### Retrieval flow for conceptual queries\n\nsearch_documents (existing) — unchanged, top-N chunk similarity\n\n## Cost\n\nZero additional API calls. Keywords extracted from existing text. Document embedding is mean of existing chunk vectors. Both computed at end of _chunk_embed_store.","status":"open","priority":2,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-10T05:44:54.181898-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T08:42:52.276075-08:00"}
{"id":"quarry-53v","title":"infra: Add page_type and source_format columns to LanceDB schema","description":"Add two new string columns to the LanceDB chunk schema and populate them during ingestion for all existing formats.\n\n## Schema changes\n- `page_type` (pa.utf8()) — content type: text, code, spreadsheet, presentation, email\n- `source_format` (pa.utf8()) — file extension or source indicator: .pdf, .py, .xlsx, \"inline\", etc.\n\n## Pipeline changes\n- Pass page_type through from PageContent to Chunk to LanceDB record\n- Add source_format (derived from file extension) at ingest time\n- For ingest_content (raw text ingestion), set source_format to \"inline\" to distinguish from file-sourced documents\n- Fix document_path — currently hardcoded to \"\u003cstring\u003e\" for inline content; consider a more intentional sentinel or empty string\n- Update all existing ingest functions: ingest_pdf, ingest_text_file, ingest_image, ingest_code_file, ingest_text_content\n\n## PageType redefinition\n- PDF pages: both TEXT and IMAGE extraction produce page_type=\"text\" in stored chunks\n- SECTION → \"text\" (MD, TXT, DOCX, TEX are all prose)\n- CODE stays \"code\"\n- The PageType enum in models.py may need updating or the mapping happens at storage time\n\n## Inline content provenance\n- ingest_text (to be renamed ingest_content) currently stores synthetic values: document_path=\"\u003cstring\u003e\", page_number=section index, total_pages=section count\n- These fields are semantic lies — get_page returns a \"page\" that is really a markdown heading section\n- source_format=\"inline\" makes this provenance explicit and queryable, so downstream tools can distinguish file-sourced vs inline-sourced chunks\n\n## Breaking change\nExisting indexes need re-ingestion (quarry sync) to populate new columns. Acceptable — no production users yet.","status":"closed","priority":1,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-11T06:57:51.296526-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-13T10:52:11.495829-08:00","closed_at":"2026-02-13T10:52:11.495831-08:00"}
{"id":"quarry-5oy","title":"bug: embed_texts() has no batching — OOM crash on large documents","description":"quarry sync consumed 66.3 GB resident memory on a 24 GB M2 MacBook Air, causing macOS to kill 120+ system services via Jetsam and effectively crashing the machine. Root cause: OnnxEmbeddingBackend.embed_texts() in embeddings.py processes ALL chunks for a document in a single ONNX inference call with no batching. For a 575-chunk XLSX, this creates batch shape (575, 512). With ThreadPoolExecutor(max_workers=4), up to 4 large documents embed concurrently — 1,187 chunks total, ~15 GB just for attention matrices in a single layer. Fix: add EMBED_BATCH_SIZE=32 batching loop in embed_texts(). With batch 32, attention per layer drops to 402 MB per thread (~1.6 GB for 4 threads). Also consider reducing default workers from 4 to 2. Full analysis in quarry-sync-oom-bug-report.md.","status":"closed","priority":0,"issue_type":"bug","owner":"jmf@pobox.com","created_at":"2026-02-14T12:16:49.46758-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-14T12:46:19.060462-08:00","closed_at":"2026-02-14T12:46:19.060462-08:00","close_reason":"Batched embed_texts() at 32 texts, reduced default workers to 2"}
{"id":"quarry-5sg","title":"deregister fails to clean up LanceDB chunks (document_name mismatch)","description":"When deregistering a synced collection, delete_document is called for each file in the registry. For Antz (79 Java files, 222 chunks in LanceDB), every call returned 0 chunks deleted — yet quarry delete-collection Antz (which filters by collection only) successfully deleted all 222. This means the document_name values in the SQLite registry do not match those in LanceDB. The chunks become orphaned. Needs reproduction: register a small directory, sync, deregister, check if chunks remain.","status":"closed","priority":2,"issue_type":"bug","owner":"jmf@pobox.com","created_at":"2026-02-15T17:46:44.802978-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-24T12:47:46.655383-08:00","closed_at":"2026-02-24T12:47:46.655383-08:00","close_reason":"Fixed: threaded document_name through code, text, and HTML processors"}
{"id":"quarry-62k","title":"pipeline: Epic 8 — Ingestion performance","description":"Scalable ingestion for 1000s of documents. Content hashing for skip-if-unchanged, directory registration with incremental re-indexing, parallel multi-document ingestion, exponential backoff for Textract polling. Depends on Epic 6 (complete).","status":"closed","priority":1,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-08T19:41:16.158214-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.996893-08:00","closed_at":"2026-02-09T04:50:06.993624-08:00","close_reason":"Merged PR #1: directory registration, incremental sync, exponential backoff, CLI/MCP tools. 245 unit + 21 integration tests."}
{"id":"quarry-65r","title":"infra: Rename beads prefix from ocr- to quarry-","description":"The beads issue prefix is still 'ocr-' from the original project name. Investigate whether beads supports renaming the prefix, and if so, migrate all existing issues to use 'quarry-' prefix.","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-10T04:58:36.866565-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:35.362258-08:00","closed_at":"2026-02-11T06:24:35.362258-08:00","close_reason":"Renamed 44 issues from ocr- to quarry- prefix"}
{"id":"quarry-66p","title":"infra: Epic 7 — Package distribution and CLI","description":"Turn quarry-mcp into a proper installable Python package with setup/diagnostic CLI commands.\n\n## Package Distribution\n- Publish to PyPI (or at minimum, installable via `pip install .` / `uv pip install .`)\n- Entry point script so `quarry` command works after install (no `uv run python -m quarry`)\n- Clean dependency specification in pyproject.toml (separate core vs optional deps)\n\n## CLI Commands\n- `quarry install`: First-run setup — download embedding model, create data directory, verify AWS credentials, configure MCP server registration\n- `quarry doctor`: Diagnostic command — check Python version, verify dependencies installed, test AWS connectivity, verify embedding model cached, check LanceDB path writable, report MCP server status","status":"closed","priority":2,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-08T13:43:59.64367-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.001275-08:00","closed_at":"2026-02-08T13:59:31.50876-08:00","close_reason":"Implemented: version management, data path fix, doctor command, install command"}
{"id":"quarry-6x0","title":"Unified ingest command dispatching on URI scheme","description":"Replace ingest-file and ingest-url with a single `ingest \u003curi\u003e` command that dispatches on scheme:\n\n- `/path/to/file.pdf` or `file:///path/to/file.pdf` → local file ingestion (existing pipeline)\n- `https://docs.example.com/page` → URL fetch + HTML ingestion\n\nDeprecate ingest-file and ingest-url once the unified command ships. Keep them as aliases during a transition period.\n\nThe MCP surface follows the same pattern: a single `ingest` tool replacing `ingest_file`, `ingest_url`, and potentially `ingest_content` (with a content:// scheme or inline detection).\n\nMotivation: file paths and URLs are both URIs pointing at resources. Separate commands for each scheme is an API seam that adds cognitive load without adding capability.","status":"open","priority":3,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-14T16:48:08.318892-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-14T16:48:08.318892-08:00","dependencies":[{"issue_id":"quarry-6x0","depends_on_id":"quarry-pcr","type":"blocks","created_at":"2026-02-14T16:48:08.52958-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-77n","title":"pipeline: Skip macOS resource fork files and .Trash during sync","description":"Sync walker picks up macOS ._* resource fork files and .Trash directories. These cause 'Failed to open file' errors (14 files) and Textract InvalidParameter errors (9 files from .Trash PNGs). Fix: skip files matching ._* prefix and .Trash directories in the directory walker.","status":"closed","priority":1,"issue_type":"bug","owner":"jmf@pobox.com","created_at":"2026-02-09T07:56:04.312826-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.996065-08:00","closed_at":"2026-02-09T08:24:45.831592-08:00","close_reason":"Fixed in PR #4. discover_files now skips dotfiles, resource forks, and hidden directories."}
{"id":"quarry-7hk","title":"Layer 1: auto-ingest fetched URLs (PostToolUse WebFetch)","description":"PostToolUse hook on WebFetch that auto-ingests fetched URLs into a web-captures collection. Reads URL from tool input JSON, dedup check against existing documents, background ingestion. High signal (you only fetch what you need), low volume (5-20/session).","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-24T11:05:19.248233-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-24T16:56:00.208054-08:00","closed_at":"2026-02-24T16:56:00.208054-08:00","close_reason":"Closed","dependencies":[{"issue_id":"quarry-7hk","depends_on_id":"quarry-dpu","type":"blocks","created_at":"2026-02-24T11:05:25.163411-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-7pv","title":"tool: Optimize MCP response sizes","description":"Large MCP responses (~12.5k tokens) observed filling context quickly.\n\n## Root cause\n\nExhaustive queries forced through top-N chunk search — addressed by ocr-4xq (hybrid document-level search).\n\n## Residual optimization for search_documents\n\nEven for conceptual queries, chunk-level search responses are larger than necessary:\n- Truncate text field in results (e.g. 200 chars with ellipsis) — callers can use get_page for full text\n- Drop chunk_index from results (rarely useful to callers)\n- Consider default limit=5 instead of 10\n- Consider a brief=true flag for compact responses\n\nThese are independent of ocr-4xq and worth doing regardless.","status":"open","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-10T04:56:16.965539-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T08:42:52.377094-08:00","dependencies":[{"issue_id":"quarry-7pv","depends_on_id":"quarry-4xq","type":"blocks","created_at":"2026-02-10T05:52:33.02074-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-7qe","title":"Cloud embedding backend (SageMaker) for fast batch ingestion","description":"Deploy the same snowflake-arctic-embed-m-v1.5 model to a SageMaker Serverless Inference endpoint for batch ingestion. Local ONNX stays for queries. Same model, same 768-dim vectors, same embedding space — cloud for throughput during sync, local for latency during search.\n\nMotivation: local ONNX embedding sustains ~11 chunks/s (benchmarked). A 10K-file sync takes ~2 hours. Offloading embedding to cloud creates network I/O that parallelizes (same principle as Textract OCR).\n\nDesign:\n- Add SageMakerEmbeddingBackend implementing EmbeddingBackend protocol\n- Configure via EMBEDDING_BACKEND=sagemaker env var (default remains local)\n- sync.py uses cloud backend when configured; search/MCP always uses local\n- Workers \u003e1 become useful again when embedding is network-bound\n- SageMaker Serverless scales to zero when idle (no cost between syncs)\n\nKey constraint: must use identical model weights so vectors are compatible between ingest and query paths.","status":"closed","priority":2,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-14T16:16:37.414729-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-14T19:23:50.417933-08:00","closed_at":"2026-02-14T19:23:50.417933-08:00","close_reason":"SageMaker embedding backend shipped in PR #39"}
{"id":"quarry-7ua","title":"infra: Rename beads prefix (duplicate)","description":"Beads issues use ocr- prefix from the original project name. Project is now quarry-mcp. Rename prefix to quarry- for consistency. Check if bd supports prefix migration or if issues need manual recreation.","status":"closed","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-09T07:17:57.450816-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.003317-08:00","closed_at":"2026-02-10T05:02:01.078932-08:00","close_reason":"Duplicate of ocr-65r"}
{"id":"quarry-81v","title":"Respect .gitignore and ignore conventions during directory sync","description":"discover_files() in sync.py uses rglob('*') and only skips dotfiles. It indexes venv/, node_modules/, __pycache__/, build/, dist/, and all other gitignored content. This wastes time, disk, and pollutes search results with third-party code.\n\nFix: teach discover_files() to respect ignore conventions:\n1. .gitignore (nested, standard gitignore spec via pathspec library)\n2. .quarryignore (project-level, same syntax)\n3. Hardcoded defaults: node_modules/, __pycache__/, .venv/, venv/, .tox/, .nox/, .eggs/, *.egg-info/, dist/, build/\n\nUse the pathspec library (already used by Black/pre-commit) for gitignore-compatible pattern matching. The change is isolated to discover_files() — callers don't change.\n\nAcceptance criteria:\n- discover_files() skips files matching .gitignore patterns at any level\n- discover_files() skips files matching .quarryignore if present\n- Hardcoded defaults always apply (even without .gitignore)\n- Existing tests pass; new tests cover ignore behavior\n- Quality gates green","status":"closed","priority":1,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-15T17:13:05.518845-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-15T17:48:25.233129-08:00","closed_at":"2026-02-15T17:48:25.233129-08:00","close_reason":"PR #45 merged: .gitignore, .quarryignore, and hardcoded defaults respected during sync"}
{"id":"quarry-8bb","title":"feat: add quarry serve HTTP server command","status":"closed","priority":1,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-13T17:03:48.708834-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-13T17:12:05.001709-08:00","closed_at":"2026-02-13T17:12:05.001709-08:00","close_reason":"Closed"}
{"id":"quarry-8ee","title":"feat: HotkeyManager global shortcut (Cmd+Shift+Q)","status":"closed","priority":1,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-13T17:03:53.161635-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-13T18:09:54.203696-08:00","closed_at":"2026-02-13T18:09:54.203696-08:00","close_reason":"Closed","dependencies":[{"issue_id":"quarry-8ee","depends_on_id":"quarry-wzu","type":"blocks","created_at":"2026-02-13T17:03:59.752198-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-8g0","title":"docs: Search quality and tuning guide","description":"Add documentation on search quality tuning: when to adjust CHUNK_MAX_CHARS and CHUNK_OVERLAP_CHARS, when Textract is worth using vs local OCR, how the embedding model (snowflake-arctic-embed-m-v1.5) affects results, and general tips for getting better search results.","status":"closed","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-13T06:08:12.407698-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-14T07:26:06.056541-08:00","closed_at":"2026-02-14T07:26:06.056541-08:00","close_reason":"Closed"}
{"id":"quarry-8nu","title":"tool: Sitemap crawling for bulk URL ingestion","description":"Parse sitemap.xml to discover URLs, then batch-ingest each page using URL ingestion. Supports documentation sites, blogs, reference manuals. Depends on URL ingestion feature. Add as MCP tool (ingest_sitemap) and CLI command.","status":"closed","priority":4,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-09T11:43:00.146025-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-23T14:57:12.059023-08:00","closed_at":"2026-02-23T14:57:12.059023-08:00","close_reason":"Implemented: sitemap parser, pipeline orchestrator with lastmod dedup, CLI command, MCP tool, 27 tests","dependencies":[{"issue_id":"quarry-8nu","depends_on_id":"quarry-pcr","type":"blocks","created_at":"2026-02-09T11:43:08.895941-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-8si","title":"epic: Search-by-format — persist content type and source format in chunks","description":"Enable end users to filter semantic searches by document format (e.g. \"find spreadsheets with DCF models\"). Requires coordinated changes across schema, ingestion pipeline, and search.\n\n## Design Decisions (settled)\n\n### PageType redefined as content type (Option A)\nPageType becomes a **content type** classification, not an extraction method. The TEXT/IMAGE distinction for PDF pages (which described extraction routing) is dropped from stored metadata. After extraction, all prose chunks are the same regardless of whether they came from PyMuPDF or Textract.\n\nStored PageType values:\n- `text` — prose documents (PDF, MD, TXT, DOCX, TEX, OCR results)\n- `code` — source code (tree-sitter split)\n- `spreadsheet` — tabular data (XLSX, CSV)\n- `presentation` — slides (PPTX)\n- `email` — structured messages (EML/MBOX, future)\n\nThe PDF analyzer still uses TEXT/IMAGE internally for pipeline routing; that classification does not propagate to chunks.\n\n### Two new chunk schema columns\n1. **`page_type`** (string) — content type from the enum above. Coarse filter: \"show me only spreadsheets.\"\n2. **`source_format`** (string) — file extension (`.pdf`, `.py`, `.xlsx`). Precise filter: \"show me only Excel files.\"\n\nBoth stored as LanceDB columns, filterable via SQL WHERE clauses in search.\n\n### XLSX stored as LaTeX tabular\nSpreadsheet content is serialized as LaTeX `\\begin{tabular}` via `pandas.DataFrame.to_latex()`. This reuses the existing LaTeX-aware text_processor for chunking, and LLMs parse LaTeX tables natively.\n\n### Search API\n`search_documents` gains optional `page_type` and `source_format` filter parameters, implemented as LanceDB WHERE clauses.\n\n## Constituent work\n- Schema: add `page_type` and `source_format` columns to LanceDB schema\n- Pipeline: persist both fields during ingestion for all existing formats\n- XLSX ingestion: new spreadsheet_processor using pandas + openpyxl, LaTeX output\n- Search: expose filter parameters in MCP tool and CLI\n- Backfill: existing indexed documents need re-ingestion (quarry sync) to populate new columns","status":"closed","priority":1,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-11T06:57:13.533993-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-14T16:21:24.883202-08:00","closed_at":"2026-02-14T16:21:24.883202-08:00","close_reason":"All constituent work shipped: schema columns (quarry-53v), XLSX ingestion (quarry-91r), search filters (quarry-mo5), PPTX ingestion (quarry-ebv)","dependencies":[{"issue_id":"quarry-8si","depends_on_id":"quarry-53v","type":"blocks","created_at":"2026-02-11T08:17:29.207735-08:00","created_by":"\"jmf-pobox\""},{"issue_id":"quarry-8si","depends_on_id":"quarry-mo5","type":"blocks","created_at":"2026-02-11T08:17:29.335745-08:00","created_by":"\"jmf-pobox\""},{"issue_id":"quarry-8si","depends_on_id":"quarry-91r","type":"blocks","created_at":"2026-02-11T08:17:29.4734-08:00","created_by":"\"jmf-pobox\""},{"issue_id":"quarry-8si","depends_on_id":"quarry-ebv","type":"blocks","created_at":"2026-02-11T08:17:29.616355-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-91r","title":"format: XLSX/XLS spreadsheet ingestion","description":"Ingest Excel spreadsheets into quarry.\n\n## Design Decisions (settled)\n\n### Serialization: LaTeX tabular\nSpreadsheet content is serialized as LaTeX `\\begin{tabular}` via `pandas.DataFrame.to_latex()`. This reuses the existing LaTeX-aware text_processor for chunking, and LLMs parse LaTeX tables natively. Same approach applies to CSV.\n\n### Chunking strategy\nOne LaTeX tabular block per sheet. Large sheets (\u003e1800 chars after LaTeX conversion) get split by row groups with column headers repeated in each chunk.\n\n### Libraries\n- `pandas` — already a transitive dependency of sentence-transformers (free)\n- `openpyxl` — XLSX backend for pandas (~4 MB, new explicit dependency)\n\n### PageType\nChunks get `page_type=\"spreadsheet\"` and `source_format=\".xlsx\"` (or `.csv`, `.xls`).\n\n### Scope\n- New `spreadsheet_processor.py` module\n- Add `.xlsx`, `.xls`, `.csv` to SUPPORTED_EXTENSIONS\n- Serialize via pandas to_latex(), feed into text_processor for chunking\n- Persist page_type and source_format in chunks\n- Handle: multiple sheets (chunk per sheet), merged cells (flatten), formulas (value only)\n- Depends on schema columns existing (quarry-8si epic)","status":"closed","priority":1,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-09T05:35:40.729921-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-14T08:10:42.296088-08:00","closed_at":"2026-02-14T08:10:42.296088-08:00","close_reason":"Closed","dependencies":[{"issue_id":"quarry-91r","depends_on_id":"quarry-53v","type":"blocks","created_at":"2026-02-11T06:57:57.228366-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-92y","title":"Replace sentence-transformers with direct ONNX inference","description":"sentence-transformers pulls in torch (~2.5GB), transformers, scikit-learn, scipy. We already ship onnxruntime for rapidocr. The snowflake-arctic-embed-m-v1.5 model has an ONNX export available. Replace sentence-transformers with: (1) tokenizers for text tokenization, (2) onnxruntime for inference. This eliminates torch, transformers, scikit-learn, scipy, sympy, mpmath, networkx — roughly 2.5GB and ~40 transitive deps from every install. No API change, no behavior change — just a smaller dependency footprint.","status":"closed","priority":1,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-12T09:50:05.791908-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-12T18:18:49.79055-08:00","closed_at":"2026-02-12T18:18:49.79055-08:00","close_reason":"Merged PR #16: replaced sentence-transformers with ONNX Runtime"}
{"id":"quarry-9d4","title":"docs: Contributing guide and link design docs","description":"Create a CONTRIBUTING.md with guidance on adding new formats, architecture decisions, and PR process. Link the existing docs/BACKEND-ABSTRACTION.md and docs/NON-FUNCTIONAL-DESIGN.md from the README or contributing guide so they are discoverable.","status":"closed","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-13T06:08:12.232325-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-14T07:26:06.055067-08:00","closed_at":"2026-02-14T07:26:06.055067-08:00","close_reason":"Closed"}
{"id":"quarry-9ey","title":"Add list_databases and use_database MCP tools","description":"The MCP server binds to a single database at startup via _db_name. There is no way for an LLM to discover or switch databases mid-session. The CLI has 'quarry databases' and '--db' on every command. Add list_databases (discover named databases under QUARRY_ROOT) and use_database (set _db_name for subsequent calls) MCP tools to close this gap.","status":"closed","priority":2,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-14T17:47:06.74141-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-15T18:20:31.193467-08:00","closed_at":"2026-02-15T18:20:31.193467-08:00","close_reason":"PR #46 merged: list_databases and use_database MCP tools"}
{"id":"quarry-9z5","title":"app: macOS menu bar companion app","description":"Native macOS menu bar app that surfaces Quarry search to non-CLI users. Highest-leverage item for widening the discovery funnel and making retrieval visible (see prfaq.pdf Value risk). Users see what Quarry finds, creating shareable moments that drive word-of-mouth. Complements the CLI and MCP server — same database, different interface.","status":"closed","priority":1,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-13T16:51:47.430939-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-13T18:14:24.197104-08:00","closed_at":"2026-02-13T18:14:24.197104-08:00","close_reason":"Closed"}
{"id":"quarry-a0b","title":"docs: Link CHANGELOG and add coverage badge to README","description":"Link CHANGELOG.md from the README (e.g. a Changelog section or badge). Add a test coverage badge — the project already uses pytest-cov and has .coverage but no visibility in the README.","status":"closed","priority":4,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-13T06:08:12.571136-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-14T07:26:06.058022-08:00","closed_at":"2026-02-14T07:26:06.058022-08:00","close_reason":"Closed"}
{"id":"quarry-a9v","title":"infra: Backend abstraction Phase 1 — Protocols and factory","description":"Extract OcrBackend and EmbeddingBackend protocols from existing code. Wrap current functions in backend classes. Create factory with caching.\n\n## Scope (from docs/BACKEND-ABSTRACTION.md Phase 1)\n\n1. Add OcrBackend and EmbeddingBackend protocols to types.py\n2. Add TextractOcrBackend class to ocr_client.py (wraps ocr_document_via_s3, ocr_image_bytes)\n3. Add SnowflakeEmbeddingBackend class to embeddings.py (wraps embed_texts, embed_query, owns model cache)\n4. Create backends.py with get_ocr_backend() and get_embedding_backend() factory functions\n5. Add ocr_backend setting to config.py\n6. Tests for new classes and factory\n\n## Files\n\n- src/quarry/types.py — MODIFY (add 2 protocols)\n- src/quarry/ocr_client.py — MODIFY (add TextractOcrBackend class)\n- src/quarry/embeddings.py — MODIFY (add SnowflakeEmbeddingBackend class)\n- src/quarry/backends.py — NEW (~40 lines)\n- src/quarry/config.py — MODIFY (add ocr_backend field)\n- tests/test_backends.py — NEW\n\n## Does NOT include\n\n- Pipeline wiring (Phase 2)\n- MCP/CLI call-site changes (Phase 2)\n- Audio transcription protocol (Phase 3)\n- Local OCR implementation (Phase 4)","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-09T05:30:41.904627-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.000732-08:00","closed_at":"2026-02-09T06:14:17.766994-08:00","close_reason":"Phase 1 complete: 2 protocols, 2 backend classes, thread-safe factory, 12 tests"}
{"id":"quarry-aqc","title":"get_page returns 'No data found' for large documents","status":"closed","priority":2,"issue_type":"bug","owner":"jmf@pobox.com","created_at":"2026-02-24T13:20:16.928236-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-24T13:20:23.062583-08:00","closed_at":"2026-02-24T13:20:23.062583-08:00","close_reason":"Fixed: added _FULL_SCAN_LIMIT to all non-vector LanceDB queries"}
{"id":"quarry-axj","title":"format: Epic 2 — Text document ingestion","description":"Direct ingestion of text-based formats without OCR.\n\n- Plain text files (.txt)\n- Markdown (.md)\n- LaTeX (.tex)\n- DOCX (via python-docx or similar)\n- Configurable page/section boundary detection\n- String ingestion: ingest raw text/markdown/HTML from clipboard, web pages, or chat context (no file required)","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T09:19:14.846313-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.002538-08:00","closed_at":"2026-02-08T11:11:59.562506-08:00","close_reason":"Text document ingestion implemented: .txt, .md, .tex, .docx files + raw string ingestion via MCP"}
{"id":"quarry-b0j","title":"pipeline: PII detection and redaction","description":"Prevent PII from reaching LLM context windows via ingestion-time detection and retrieval-time redaction. Secure by default (on by default, opt-out).\n\n## Threat Model\n\nUsers unknowingly send PII to LLMs through MCP responses. quarry stores invoices, contracts, and personal documents containing names, addresses, emails, phone numbers, and financial account numbers.\n\n## Design\n\n### Ingestion-time detection\n- After chunking, run Microsoft Presidio analyzer on each chunk's text\n- Store detected PII spans as metadata: entity type, start offset, end offset\n- Store as JSON column (pii_spans) on each chunk row in LanceDB\n- Also detect on page_raw_text separately (different offsets than chunk text)\n- Embeddings computed on full unredacted text — preserves search quality\n\n### Retrieval-time redaction\n- Before returning MCP responses, apply stored spans to replace PII with placeholders\n- Placeholder style: [PERSON], [EMAIL], [PHONE], [ADDRESS], etc. (Presidio standard)\n- Applies to both search_documents results and get_page responses\n- Toggle: pii_redaction setting in Settings, True by default\n\n### Audit tool\n- New MCP tool: find documents/chunks containing specific PII entity types\n- Query stored pii_spans metadata across all chunks\n- Example: 'which documents contain PHONE_NUMBER entities'\n\n## Schema Addition\n\nNew column on chunks table:\n  pii_spans: utf8 (JSON string)\n  pii_spans_raw: utf8 (JSON string, for page_raw_text)\n\nExample value:\n  [{\"type\": \"PERSON\", \"start\": 42, \"end\": 55}, {\"type\": \"EMAIL\", \"start\": 120, \"end\": 148}]\n\n## Dependencies\n\n- Microsoft Presidio as optional dependency: quarry[pii] extra\n- Presidio wraps spaCy + regex recognizers, runs locally, no API cost\n- PII entity types: PERSON, EMAIL_ADDRESS, PHONE_NUMBER, LOCATION/ADDRESS, CREDIT_CARD, US_SSN, IBAN, and others from Presidio defaults\n\n## Configuration\n\n- pii_redaction: bool = True (secure by default)\n- pii_entity_types: list of entity types to detect (default: all Presidio defaults)\n- Per-collection config deferred\n\n## Commits (rough)\n\n1. Add Presidio as optional dependency, pii_redaction setting\n2. Add pii_spans/pii_spans_raw columns to LanceDB schema\n3. PII detection module wrapping Presidio analyzer\n4. Integrate detection into _chunk_embed_store pipeline\n5. Retrieval-time redaction in search and get_page MCP responses\n6. Audit MCP tool: query PII spans across chunks\n7. Tests for detection, redaction, and audit","status":"open","priority":2,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-10T06:31:35.378665-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T08:42:52.178377-08:00"}
{"id":"quarry-bc2","title":"Document expiration/TTL for web-captures collection","description":"Add optional TTL/expiration for documents, especially web-captures. ingestion_timestamp is already stored but never checked. Options: max-age per collection, LRU eviction by collection size, or manual quarry prune command. Low priority since typical session captures are 5-20 URLs.","status":"open","priority":4,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-24T16:49:40.30618-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-24T16:49:45.89943-08:00"}
{"id":"quarry-bez","title":"format: Email ingestion (EML/MBOX)","description":"Ingest email files into quarry.\n\n## Approach\n- stdlib email module parses EML and MBOX formats\n- Extract: subject, from, to, date, body (plain text and/or HTML→text)\n- Recurse into attachments: ingest supported formats (PDF, DOCX, images, etc.) as separate documents\n- One chunk per email message, or split long bodies\n- MBOX files contain multiple messages — each becomes a separate document or chunk\n\n## Scope\n- New parser module or addition to text_processor.py\n- Add .eml, .mbox to SUPPORTED_EXTENSIONS\n- Attachment handling reuses existing ingest_document pipeline\n- No new dependencies (stdlib email, html.parser)\n- No new protocol needed","status":"open","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-09T05:36:21.19669-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.004337-08:00"}
{"id":"quarry-bsj","title":"pipeline: Handle concurrent table creation race condition","description":"First file in sync fails with 'Table ocr_chunks already exists' when multiple workers try to create the table simultaneously. Fix: use create-if-not-exists pattern or catch the error and retry.","status":"closed","priority":2,"issue_type":"bug","owner":"jmf@pobox.com","created_at":"2026-02-09T07:56:11.466845-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.999166-08:00","closed_at":"2026-02-09T17:51:38.691813-08:00","close_reason":"Fixed with double-checked locking in insert_chunks. PR #8."}
{"id":"quarry-bww","title":"infra: Add missing Raises docstring sections","description":"Multiple public functions raise or propagate exceptions but lack Raises: docstring sections. Files: ocr_client.py (ocr_pdf_pages), embeddings.py (embed_texts, embed_query), database.py (get_db, insert_chunks, search, get_page_text, delete_document), text_processor.py (process_text_file — missing FileNotFoundError, UnicodeDecodeError), pdf_analyzer.py (analyze_pdf), text_extractor.py (extract_text_pages). See NON-FUNCTIONAL-DESIGN.md Rule 5.","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T12:11:59.136979-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.001525-08:00","closed_at":"2026-02-08T12:30:15.667497-08:00","close_reason":"Closed"}
{"id":"quarry-cdv","title":"tool: Add status/health tool to MCP server","description":"local-rag exposes a status tool (document count, chunk count, memory usage, search mode). Quarry should expose similar diagnostics.\n\n- Total documents and chunks\n- Database path and size on disk\n- Embedding model name and dimension\n- Uptime or version","status":"closed","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T10:12:58.767725-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.00532-08:00","closed_at":"2026-02-08T10:29:34.964385-08:00","close_reason":"Closed"}
{"id":"quarry-cjs","title":"pipeline: Add exception handling at system boundaries","description":"All 6 MCP tool handlers in mcp_server.py and all 4 CLI commands in __main__.py let raw tracebacks escape to users. Each boundary handler should catch expected exceptions (FileNotFoundError, ValueError, RuntimeError, TimeoutError), log with logger.exception(), and return user-friendly messages. See NON-FUNCTIONAL-DESIGN.md Rule 7.","status":"closed","priority":1,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T12:11:59.13632-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.997441-08:00","closed_at":"2026-02-08T12:21:55.714433-08:00","close_reason":"Closed"}
{"id":"quarry-ctj","title":"chore: Pin embedding model version and reduce HuggingFace network calls","description":"## Problem\n\nEvery quarry operation that loads the embedding model makes HTTP requests to HuggingFace Hub to check for updates, even when the model is already cached locally. This adds latency, requires network access, and generates \"unauthenticated requests\" warnings.\n\nAdditionally, the model version is not pinned — `sentence_transformers.SentenceTransformer(\"Snowflake/snowflake-arctic-embed-m-v1.5\")` downloads whatever the latest revision is.\n\n## Questions to investigate\n\n1. Can we pin to a specific git revision/commit hash for reproducibility?\n2. Can we set `local_files_only=True` after `quarry install` to skip network checks?\n3. Should we vendor the model or use a content-addressed cache?\n4. Are there other dependencies making unnecessary network calls at runtime?","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-11T18:58:46.858047-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T19:54:51.411637-08:00","closed_at":"2026-02-11T19:54:51.411637-08:00","close_reason":"Shipped in v0.4.1. Pinned revision e58a8f75, local_files_only=True. 4s→0.6s first load."}
{"id":"quarry-cxs","title":"Optional dependency groups for format-specific capabilities","description":"Every user pays the full dependency cost for every capability (OCR, AWS, code parsing, DOCX) even if they only ingest text files. Move format-specific deps behind optional extras: quarry-mcp[ocr], quarry-mcp[aws], quarry-mcp[code], quarry-mcp[docx], quarry-mcp[all]. Requires: graceful import errors with clear messages, quarry doctor surfacing what's installed vs available, possibly quarry install prompting for extras. UX design is the open question — how to make optional deps discoverable without frustrating users who hit missing-capability errors.","status":"open","priority":3,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-12T09:50:29.867391-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-12T09:50:29.867391-08:00"}
{"id":"quarry-d0k","title":"Claude Desktop Extension (.mcpb) install path","description":"Create a manifest.json and build-mcpb.sh for quarry-mcp so Claude Desktop users can install via double-click (.mcpb file).\n\nReference implementation: ../langlearn-polly-mcp/ (manifest.json, scripts/build-mcpb.sh)\n\nmanifest.json needs:\n- server config: uv-based, entry point for quarry mcp server\n- user_config: output_dir (QUARRY_ROOT), optionally OCR_BACKEND, AWS keys\n- tools: all 14 MCP tools declared\n- metadata: description, keywords, license, etc.\n\nBuild:\n- scripts/build-mcpb.sh using @anthropic-ai/mcpb pack\n- Attach .mcpb to GitHub releases\n- README Quick Start: download .mcpb, double-click, done\n\nThis enables the primary user persona: Claude Desktop users who never touch a terminal. The Quick Start should lead with this path.\n\nAcceptance criteria:\n- manifest.json validates\n- mcpb pack produces a working bundle\n- Double-click install in Claude Desktop works\n- quarry install still works as CLI alternative\n- README Quick Start rewritten: Desktop (.mcpb) first, CLI second","status":"closed","priority":1,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-15T16:47:30.486043-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-15T17:10:34.786125-08:00","closed_at":"2026-02-15T17:10:34.786125-08:00","close_reason":"PR #44 merged — .mcpb install path shipped"}
{"id":"quarry-dcg","title":"format: Source code language-aware ingestion","description":"Source code already works as .txt but chunking is naive. Language-aware splitting by function/class boundaries would produce better semantic chunks. Tree-sitter or simple regex-based splitting. Low priority — code search is a different problem space.","status":"closed","priority":4,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-09T05:36:30.07829-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.006051-08:00","closed_at":"2026-02-10T12:33:30.133948-08:00","close_reason":"Merged PR #10, released v0.3.0. Tree-sitter required dependency, 30+ languages, 20 tests."}
{"id":"quarry-dec","title":"feature: quarry sync --watch for live filesystem monitoring","description":"Add a --watch flag to quarry sync that uses FSEvents (macOS) / inotify (Linux) to monitor registered directories and re-ingest changed files in real time. Runs in the foreground, killed when done. Important for coding use cases where source code changes frequently during active work sessions and the LLM needs up-to-date indexed content. Lighter than a full daemon — no background service, no PID management. Consider watchdog library for cross-platform filesystem events.","status":"open","priority":2,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-13T06:37:16.269786-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-13T06:37:16.269786-08:00"}
{"id":"quarry-dpu","title":"quarry hooks CLI subcommand dispatcher","description":"Add 'quarry hooks \u003cevent\u003e' subcommand group following Entire.io's pattern. Thin CLI dispatcher that delegates to internal functions. Subcommands: session-start, post-web-fetch, pre-compact. Each reads hook stdin JSON, acts, returns JSON stdout. All fail-open.","status":"closed","priority":1,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-24T11:05:18.953559-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-24T16:09:04.295546-08:00","closed_at":"2026-02-24T16:09:04.295546-08:00","close_reason":"Closed"}
{"id":"quarry-ebv","title":"format: PPTX/PPT presentation ingestion","description":"Ingest PowerPoint presentations into quarry.\n\n## Design Decisions (settled)\n\n### Chunking strategy\nOne slide = one chunk. Slide title + body text + speaker notes concatenated. Natural boundary that matches how presentations are structured.\n\n### PageType\nChunks get `page_type=\"presentation\"` and `source_format=\".pptx\"`.\n\n### Tables in slides\nTables within slides serialized as LaTeX tabular (same approach as XLSX). Consistent representation for all tabular data regardless of source.\n\n### Embedded images\nPhase 1: skip. Phase 2: OCR via OcrBackend (depends on image extraction from PPTX).\n\n### Library\npython-pptx (already in dev environment, needs to become a dependency).\n\n### Scope\n- New `presentation_processor.py` module\n- Add `.pptx` to SUPPORTED_EXTENSIONS\n- Feed parsed text into existing chunk-embed-store pipeline\n- Persist page_type and source_format in chunks\n- Depends on schema columns existing (quarry-8si epic)","status":"closed","priority":2,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-09T05:36:14.380605-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-14T09:59:39.277383-08:00","closed_at":"2026-02-14T09:59:39.277383-08:00","close_reason":"PR #34 merged. PPTX ingestion complete.","dependencies":[{"issue_id":"quarry-ebv","depends_on_id":"quarry-53v","type":"blocks","created_at":"2026-02-11T06:57:57.345303-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-ee1","title":"feat: QuarryClient HTTP client with Codable models","status":"closed","priority":1,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-13T17:03:49.917028-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-13T18:01:57.371848-08:00","closed_at":"2026-02-13T18:01:57.371848-08:00","close_reason":"Closed","dependencies":[{"issue_id":"quarry-ee1","depends_on_id":"quarry-8bb","type":"blocks","created_at":"2026-02-13T17:03:58.856211-08:00","created_by":"\"jmf-pobox\""},{"issue_id":"quarry-ee1","depends_on_id":"quarry-kou","type":"blocks","created_at":"2026-02-13T17:03:58.983406-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-eh5","title":"refactor: rename ingest/ingest_text to ingest_file/ingest_content","description":"Rename MCP tools and CLI commands: ingest → ingest_file (takes a file path), ingest_text → ingest_content (takes inline content). Current names are confusing — ingest_text sounds like it ingests text files rather than receiving raw content inline. The distinction is input mechanism (path vs inline), not content type. Update MCP server, CLI, README, and tests. Breaking change acceptable at v0.4.x with no known users.","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-13T06:40:39.60953-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-14T07:13:58.520907-08:00","closed_at":"2026-02-14T07:13:58.520907-08:00","close_reason":"Closed"}
{"id":"quarry-ekd","title":"pipeline: Fix resource leaks in fitz.open","description":"pdf_analyzer.py:14 and text_extractor.py:25 open fitz.open() without try/finally. If an exception occurs during page iteration, the PDF handle leaks. Wrap in try/finally with doc.close() in the finally block. See NON-FUNCTIONAL-DESIGN.md Rule 6.","status":"closed","priority":1,"issue_type":"bug","owner":"jmf@pobox.com","created_at":"2026-02-08T12:11:59.143001-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.997179-08:00","closed_at":"2026-02-08T12:21:55.712416-08:00","close_reason":"Closed"}
{"id":"quarry-ewr","title":"connector: Google Drive integration","description":"Native Google Drive API integration for registering and syncing Google Drive folders as collections. Authenticate via OAuth2 or service account. Download files to temp storage, ingest, track sync state in registry. Supports Docs, Sheets, Slides (export as DOCX/XLSX/PPTX). Note: Google Drive for Desktop mounts work today with quarry register as a workaround.","status":"open","priority":4,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-09T11:43:04.971154-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T08:32:15.549192-08:00"}
{"id":"quarry-h9k","title":"Claude Code slash commands: /ingest, /find, /explain, /source, /quarry","description":"## Commands\n\n/ingest \u003ctarget\u003e - Smart orchestrated ingest. Claude determines the right approach:\n- Bare domain or sitemap URL -\u003e find sitemap, call ingest_sitemap\n- Single URL -\u003e call ingest_url\n- Directory path -\u003e register_directory + sync_all_registrations\n- File path -\u003e call ingest_file\n- No args -\u003e ask what to ingest\n\n/find \u003cquery\u003e - Retrieve relevant passages with sources. Calls search_documents, presents results with document names, page numbers, and similarity. Offers to pull full page context via get_page.\n\n/explain \u003ctopic\u003e - Synthesize understanding from indexed docs. Searches, reads full pages for top results, produces a coherent explanation citing sources. Multi-step orchestration: search -\u003e get_page -\u003e synthesize.\n\n/source \u003cclaim\u003e - Provenance lookup. Where did I read about X? Finds the original document and page, shows the full passage in context. Focuses on exact location rather than breadth.\n\n/quarry - Status dashboard and management:\n- /quarry (no args) -\u003e list_collections + status summary\n- /quarry sync -\u003e sync_all_registrations\n- /quarry doctor -\u003e runs quarry doctor via bash\n\nEach command gets a prod variant (commands/find.md) and a dev variant (commands/find-dev.md) per dual-mode standard.\n\n## Output Formatting (biff DES-001 pattern)\n\nAdopt biff three-layer display architecture for all quarry MCP tool output.\n\n### PostToolUse hook (suppress-output.sh)\nIntercepts all quarry MCP tool responses. Splits into two channels:\n- updatedMCPToolOutput: compact summary for the tool result panel\n- additionalContext: full formatted output for the LLM to emit verbatim\n\n### Silent commands (action confirmations, no LLM output needed)\n- ingest_file: \"31 chunks indexed from report.pdf\"\n- ingest_url: \"31 chunks indexed from https://...\"\n- ingest_content: \"1 chunk indexed from notes.md\"\n- delete_document: \"Deleted smoke-test-inline.md (1 chunk)\"\n- delete_collection: \"Deleted smoke-test (171 chunks)\"\n- register_directory, deregister_directory: confirmation line\n- use_database: \"Switched to work\"\n\n### Data commands (summary in panel, full output via additionalContext)\n- search_documents: panel \"3 results in smoke-test\" / full formatted result list with doc name, page, snippet\n- get_documents: panel \"5 documents\" / document table with names, chunks, timestamps\n- list_collections: panel \"4 collections\" / collection table with counts\n- get_page: panel \"p.2 of report.pdf\" / full page text\n- ingest_sitemap: panel \"5 ingested, 0 skipped\" / progress log + per-URL results\n- sync_all_registrations: panel \"synced 3 directories\" / per-directory results\n- list_registrations: panel \"3 registered\" / directory table\n- list_databases: panel \"2 databases\" / database table with sizes\n- status: panel \"default: 6 docs, 430 chunks\" / full stats\n\n### MCP server instructions field\nFormatting guidance in the MCP server instructions (loads at initialize handshake, before any tool calls). This is critical - biff learned that skill prompt wording alone is insufficient; the instructions field provides prior-context delivery that makes verbatim formatting work.\n\n### Formatter\nShared formatter for table output (adapted from biff DES-014). 80-column constrained tables for LLM consumption.\n\n## References\n- biff DESIGN.md DES-001 (three-layer display architecture, 12-16h of iteration)\n- biff DESIGN.md DES-014 (column-constrained table formatter)\n- biff hooks/suppress-output.sh as reference implementation","status":"closed","priority":2,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-23T22:07:01.986772-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-24T01:52:43.942634-08:00","closed_at":"2026-02-24T01:52:43.942634-08:00","close_reason":"PR #58 merged: slash commands, formatted output, PostToolUse hook","dependencies":[{"issue_id":"quarry-h9k","depends_on_id":"quarry-mlw","type":"blocks","created_at":"2026-02-23T22:07:11.536373-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-ht2","title":"Layer 2: capture compaction summaries (PreCompact)","description":"PreCompact hook that captures the session summary before compaction. Ingests as a searchable document in session-notes collection. First: verify what data PreCompact exposes in hook stdin.","status":"closed","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-24T11:05:19.372838-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-24T21:20:08.159211-08:00","closed_at":"2026-02-24T21:20:08.159211-08:00","close_reason":"Closed","dependencies":[{"issue_id":"quarry-ht2","depends_on_id":"quarry-dpu","type":"blocks","created_at":"2026-02-24T11:05:25.284598-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-imv","title":"Add --json global flag to CLI","description":"Add --json global flag to CLI for machine-readable output.\n\nAdopts org standard punt-kit-64b. See punt-kit for the standard definition.","status":"open","priority":3,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-17T09:39:46.534432-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-20T09:04:08.863827-08:00"}
{"id":"quarry-jlo","title":"format: Epic 3 — Image format support","description":"OCR for standalone image files (not wrapped in PDF).\n\n- Common formats: PNG, JPG, TIFF, BMP, WebP\n- Single-image and batch ingestion\n- Image preprocessing for OCR quality (deskew, contrast)","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T09:19:15.290644-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.002289-08:00","closed_at":"2026-02-08T12:55:01.240407-08:00","close_reason":"Closed"}
{"id":"quarry-k7h","title":"tool: Expose delete_document via MCP and CLI","description":"The database layer has delete_document() but it is not exposed through the MCP server or CLI. local-rag exposes delete_file — quarry should too.\n\n- Add delete_document tool to MCP server\n- Add 'quarry delete \u003cdocument_name\u003e' CLI command\n- Confirm deletion returns feedback (e.g. chunk count removed)","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T10:12:56.56393-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.001788-08:00","closed_at":"2026-02-08T10:29:34.962562-08:00","close_reason":"Closed"}
{"id":"quarry-kfb","title":"pipeline: Epic 5 — Ingestion quality","description":"Post-processing to improve extracted text quality.\n\n- LLM-based OCR error correction\n- Chunk quality scoring and filtering\n- Duplicate and near-duplicate detection\n- Table and figure extraction","status":"closed","priority":1,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T09:19:17.214071-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.997693-08:00","closed_at":"2026-02-10T05:04:26.110793-08:00","close_reason":"Scope too vague — four unrelated projects bundled together. Duplicate detection is the only tractable item; can be re-created as a standalone task if needed."}
{"id":"quarry-kog","title":"format: EPUB ingestion","description":"Ingest EPUB ebooks. HTML chapters, strip tags, section-aware splitting. Library: ebooklib. Straightforward — same pipeline as DOCX.","status":"open","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-09T05:36:29.596769-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.00409-08:00"}
{"id":"quarry-kou","title":"chore: create quarry-menubar GitHub repo with XcodeGen scaffold","status":"closed","priority":1,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-13T17:03:49.707206-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-13T17:38:15.437895-08:00","closed_at":"2026-02-13T17:38:15.437895-08:00","close_reason":"Repo created, XcodeGen scaffold with build+test verified"}
{"id":"quarry-kt0","title":"Auto-capture configuration via plugin settings","description":"Add opt-in/out configuration for each capture layer via .claude/quarry.local.md YAML frontmatter. Settings: auto_capture.session_sync, auto_capture.web_fetch, auto_capture.compaction, auto_capture.exclude_urls patterns.","status":"closed","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-24T11:05:19.498301-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-24T23:18:45.317453-08:00","closed_at":"2026-02-24T23:18:45.317453-08:00","close_reason":"Closed"}
{"id":"quarry-l5s","title":"infra: Add DEBUG logging to database queries","description":"database.py search() and get_page_text() lack DEBUG logging. Add logger.debug for query parameters (limit, document_filter) and result counts. See NON-FUNCTIONAL-DESIGN.md DEBUG-level standard.","status":"closed","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T12:11:59.139247-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.004834-08:00","closed_at":"2026-02-08T12:30:15.666118-08:00","close_reason":"Closed"}
{"id":"quarry-lh5","title":"transform: Audio transcription backend","description":"Speech-to-text ingestion for audio content.\n\n- Audio format support: MP3, WAV, M4A, FLAC\n- AWS Transcribe or Whisper integration\n- Speaker diarization\n- Timestamped chunks for source reference","status":"open","priority":4,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T09:19:16.247327-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T08:43:01.690996-08:00"}
{"id":"quarry-lpd","title":"infra: Rename ocr_chunks table to chunks","description":"The LanceDB table is still named 'ocr_chunks' (TABLE_NAME in database.py) but the project was renamed to quarry. Rename the table constant and update all references. Consider: migration path for existing databases with data in the old table name.","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-10T04:58:07.026992-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.998656-08:00","closed_at":"2026-02-10T05:57:37.689673-08:00","close_reason":"PR #9 — renamed TABLE_NAME from ocr_chunks to chunks"}
{"id":"quarry-m3y","title":"quarry install MCP registration fails during TestPyPI testing","description":"## Problem\n\n`quarry install` registers the MCP server as `uvx --from punt-quarry quarry mcp`, which pulls from production PyPI. During the release workflow's TestPyPI testing phase (before approving to production), the MCP server fails to connect because `punt-quarry` doesn't exist on production PyPI yet.\n\nThis means the TestPyPI gate cannot fully validate the install flow — `quarry --help` passes but MCP registration is broken.\n\n## Observed\n\n```\nquarry: uvx --from punt-quarry quarry mcp - ✗ Failed to connect\n```\n\n## Root Cause\n\n`_MCP_COMMAND = \"uvx\"` and `_MCP_ARGS = [\"--from\", \"punt-quarry\", \"quarry\", \"mcp\"]` in `doctor.py` hardcode production PyPI resolution. No fallback to the already-installed binary on PATH.\n\n## Possible Fixes\n\n1. Register MCP using the local binary (`quarry mcp`) instead of `uvx` — works regardless of install source\n2. Detect install source and adjust index URL for `uvx` accordingly\n3. Accept the gap and only test MCP registration after production PyPI publish","status":"closed","priority":2,"issue_type":"bug","owner":"jmf@pobox.com","created_at":"2026-02-23T20:13:36.704039-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-24T09:15:03.828652-08:00","closed_at":"2026-02-24T09:15:03.828652-08:00","close_reason":"Obsolete: plugin architecture (quarry-h9k) replaced quarry install MCP registration. Plugin system handles MCP via .claude-plugin/plugin.json; SessionStart hook handles permissions. The old claude mcp add path is now legacy dead code."}
{"id":"quarry-m70","title":"infra: Backend abstraction Phase 2 — Pipeline wiring","description":"Replace direct function calls with factory calls. All call sites go through get_ocr_backend() and get_embedding_backend().\n\n## Scope (from docs/BACKEND-ABSTRACTION.md Phase 2)\n\n1. pipeline.py — replace ocr_document_via_s3() and embed_texts() calls with factory calls\n2. mcp_server.py — replace 2 embed_query() calls with get_embedding_backend(settings).embed_query()\n3. __main__.py — replace 1 embed_query() call with get_embedding_backend(settings).embed_query()\n4. Update test mocking (patch factory instead of module functions)\n\n## Files\n\n- src/quarry/pipeline.py — MODIFY\n- src/quarry/mcp_server.py — MODIFY\n- src/quarry/__main__.py — MODIFY\n- tests/test_pipeline.py — MODIFY (mock factory)\n- tests/test_pipeline_images.py — MODIFY (mock factory)\n- tests/test_mcp_server.py — MODIFY (mock factory)\n- tests/test_cli.py — MODIFY (mock factory)\n\n## Depends on\n\nPhase 1 (ocr-a9v): protocols, implementations, factory must exist first.","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-09T05:32:03.207114-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.000413-08:00","closed_at":"2026-02-09T06:22:21.351143-08:00","close_reason":"Pipeline, CLI, and MCP server now use backend factory. All 257 unit tests pass.","dependencies":[{"issue_id":"quarry-m70","depends_on_id":"quarry-a9v","type":"blocks","created_at":"2026-02-09T05:32:05.957727-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-mdj","title":"infra: Add rename/move operation to database layer","description":"When a file is renamed or moved, the stored document_name and document_path in LanceDB become stale. Currently sync treats this as delete + re-ingest, wasting OCR and embedding compute.\n\n## Database layer\n\nAdd rename_document() to database.py that updates document_name and document_path columns via table.update() with a WHERE filter. No re-embedding or re-chunking needed.\n\n## Sync integration\n\nIn compute_sync_plan(), after building to_delete and to_ingest lists, cross-reference them: if a deletion candidate and an ingestion candidate share the same size+mtime, treat it as a rename instead of delete+ingest. mv preserves both attributes on the same filesystem.\n\nSyncPlan gains a to_rename list of (old_record, new_path) tuples. sync_collection handles renames via rename_document() + registry update.\n\nAmbiguous case (multiple files with identical size+mtime): fall back to delete+ingest.\n\n## Three layers to update\n\n1. LanceDB — document_name and document_path columns (rename_document)\n2. SQLite registry — files table row: update path, document_name\n3. Sync engine — rename detection in compute_sync_plan, rename execution in sync_collection","status":"closed","priority":2,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-10T05:00:39.414787-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.998076-08:00","closed_at":"2026-02-10T06:20:24.31693-08:00","close_reason":"Not pursuing rename support — delete+re-ingest is acceptable. Local OCR (ocr-1ke) reduces the cost of re-ingestion, making renames a non-issue."}
{"id":"quarry-mlw","title":"Adopt prod/dev dual-mode plugin standard (scaffold)","description":"Adopt the punt-kit prod/dev dual-mode plugin standard (DES-001, plugins.md) for quarry.\n\nQuarry becomes a Claude Code plugin with the dual-mode namespace pattern:\n\n- Dev: plugin name quarry-dev, launched via claude --plugin-dir .\n- Prod: plugin name quarry, installed from marketplace\n\n## Deliverables\n\n### Plugin scaffold\n- .claude-plugin/plugin.json with name: quarry-dev, MCP server config pointing at quarry mcp\n- scripts/release-plugin.sh and scripts/restore-dev-plugin.sh per standard\n\n### Hooks\n- Hook matchers using regex quarry(_dev)? pattern for any PostToolUse formatting\n\n### Enforcement\n- punt audit passes for quarry (plugin name has -dev, release scripts exist)\n\n## References\n- punt-kit DES-001 (design record)\n- punt-kit/standards/plugins.md\n- biff as reference implementation","status":"closed","priority":2,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-23T21:51:42.320644-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-24T00:01:12.079208-08:00","closed_at":"2026-02-24T00:01:12.079208-08:00","close_reason":"PR #57 merged"}
{"id":"quarry-mo5","title":"tool: Search metadata filters","description":"Add optional filters to search_documents: page_type (content type) and source_format (file extension).\n\n## Design Decisions (settled)\n\n### Filter parameters\n- `page_type` (string, optional) — coarse content filter. Values: text, code, spreadsheet, presentation, email. Example: `page_type=\"spreadsheet\"` returns only tabular data chunks.\n- `source_format` (string, optional) — precise format filter. Values: file extensions like `.pdf`, `.py`, `.xlsx`. Example: `source_format=\".xlsx\"` returns only Excel-sourced chunks.\n\n### Implementation\nBoth filters become LanceDB SQL WHERE clauses on stored chunk columns. No post-filtering needed.\n\n### Scope\n- Add `page_type` and `source_format` parameters to `search_documents` MCP tool\n- Add `--page-type` and `--source-format` CLI flags to `quarry search`\n- Requires schema columns to exist first (depends on schema work in quarry-8si epic)\n\n## Example use case\nUser searches: \"DCF model\", source_format=\".xlsx\" → returns only spreadsheet chunks containing DCF-related content, excluding PDF slides and markdown docs that mention DCF theory.","status":"closed","priority":1,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-09T11:43:01.850212-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-13T12:17:03.763879-08:00","closed_at":"2026-02-13T12:17:03.763879-08:00","close_reason":"Implemented page_type and source_format search filters in database, MCP, and CLI layers","dependencies":[{"issue_id":"quarry-mo5","depends_on_id":"quarry-53v","type":"blocks","created_at":"2026-02-11T06:57:57.107014-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-o9k","title":"infra: Add DEBUG logging to I/O modules","description":"pdf_analyzer.py, text_extractor.py, and text_processor.py do file I/O but have no logger. Add logger = logging.getLogger(__name__) and DEBUG-level logs for: page classification decisions and thresholds (pdf_analyzer), extraction operations (text_extractor), format detection and section split counts (text_processor). See NON-FUNCTIONAL-DESIGN.md.","status":"closed","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T12:11:59.141752-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.004581-08:00","closed_at":"2026-02-08T12:30:15.664803-08:00","close_reason":"Closed"}
{"id":"quarry-osk","title":"format: HEIC image ingestion","description":"Add HEIC/HEIF image support. Apple's default camera format — 156 files in the boating library alone. macOS sips can convert to JPEG; Pillow with pillow-heif can handle cross-platform. Needs pipeline recognition of .heic/.heif extensions and conversion to a Textract-supported format (JPEG/PNG) before OCR.","status":"open","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-09T07:14:42.241905-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.003572-08:00"}
{"id":"quarry-pcr","title":"format: URL webpage ingestion","description":"Fetch a URL, extract text from HTML, and ingest as a document. Leverages existing HTML pipeline (process_html_text). Added as MCP tool (ingest_url) and CLI command (ingest-url). Uses stdlib urllib.request — no new dependencies.\n\nPR #36: https://github.com/jmf-pobox/quarry-mcp/pull/36\n\n## API design note\n\ningest-url and ingest-file are both URI-based resource ingestion — file paths and URLs are both URIs. These should eventually collapse into a single unified `ingest \u003curi\u003e` command that dispatches on scheme (file:// vs https://). When that happens, both ingest-file and ingest-url get deprecated in favor of the unified command. Track this API simplification as a follow-up.","status":"closed","priority":3,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-09T11:42:58.002882-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-14T16:55:50.445332-08:00","closed_at":"2026-02-14T16:55:50.445332-08:00","close_reason":"Shipped in PR #36. URL ingestion via ingest-url CLI and ingest_url MCP tool."}
{"id":"quarry-pil","title":"Add init subcommand for per-repo configuration","description":"Add init subcommand for per-repo collection configuration.\n\nAdopts org standard punt-kit-v9e. See punt-kit for the standard definition.","status":"open","priority":3,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-17T09:39:47.651252-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-20T09:04:18.203214-08:00"}
{"id":"quarry-pzi","title":"docs: Programmatic API documentation","description":"Document library usage with 'from quarry import ...' examples. The package is properly typed (py.typed) but only CLI and MCP interfaces are documented in the README. Add a section showing how to use the pipeline, database, and embeddings modules programmatically.","status":"closed","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-13T06:08:12.059928-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-14T07:26:06.053187-08:00","closed_at":"2026-02-14T07:26:06.053187-08:00","close_reason":"Closed"}
{"id":"quarry-q3r","title":"infra: Schema migration strategy for LanceDB","description":"When the LanceDB schema changes (new columns, type changes), existing databases break with 'No field named X' errors. Need a migration strategy: detect schema version, add missing columns with defaults, or provide a quarry migrate CLI command. Discovered during first real-world sync — old schema lacked 'collection' column.","status":"open","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-09T07:16:06.985363-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.999917-08:00"}
{"id":"quarry-r87","title":"pipeline: Handle non-UTF-8 text file encodings","description":"5 German text files failed with 'utf-8 codec can't decode byte'. These are Latin-1/CP1252 encoded. Fix: detect encoding (chardet or charset-normalizer) and decode accordingly, or fall back to latin-1 when utf-8 fails.","status":"closed","priority":2,"issue_type":"bug","owner":"jmf@pobox.com","created_at":"2026-02-09T07:56:09.555844-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.999417-08:00","closed_at":"2026-02-09T14:06:01.981067-08:00","close_reason":"Fixed in PR #6. UTF-8 → CP1252 → Latin-1 fallback chain."}
{"id":"quarry-tik","title":"Epic: Automagic knowledge capture via hooks","description":"Quarry passively captures, retains, and surfaces knowledge from Claude Code sessions via hooks. Follows Entire.io's dispatcher pattern (quarry hooks \u003cevent\u003e). See research/automagic-knowledge-capture.md for full proposal. Layers: (0) auto-index codebase on SessionStart, (1) auto-ingest fetched URLs on PostToolUse WebFetch, (2) capture compaction summaries on PreCompact.","status":"closed","priority":1,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-24T11:03:58.204746-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-24T23:18:45.319654-08:00","closed_at":"2026-02-24T23:18:45.319654-08:00","close_reason":"Closed","dependencies":[{"issue_id":"quarry-tik","depends_on_id":"quarry-dpu","type":"blocks","created_at":"2026-02-24T11:05:46.46934-08:00","created_by":"\"jmf-pobox\""},{"issue_id":"quarry-tik","depends_on_id":"quarry-306","type":"blocks","created_at":"2026-02-24T11:05:46.580105-08:00","created_by":"\"jmf-pobox\""},{"issue_id":"quarry-tik","depends_on_id":"quarry-7hk","type":"blocks","created_at":"2026-02-24T11:05:46.692695-08:00","created_by":"\"jmf-pobox\""},{"issue_id":"quarry-tik","depends_on_id":"quarry-ht2","type":"blocks","created_at":"2026-02-24T11:05:46.811088-08:00","created_by":"\"jmf-pobox\""},{"issue_id":"quarry-tik","depends_on_id":"quarry-kt0","type":"blocks","created_at":"2026-02-24T11:05:46.928597-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-tix","title":"test: integration tests for quarry serve endpoints","status":"closed","priority":1,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-13T17:03:49.480936-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-13T17:12:05.003608-08:00","closed_at":"2026-02-13T17:12:05.003608-08:00","close_reason":"Closed","dependencies":[{"issue_id":"quarry-tix","depends_on_id":"quarry-8bb","type":"blocks","created_at":"2026-02-13T17:03:58.737971-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-uae","title":"quarry schedule: launchd timer for periodic sync","description":"Add 'quarry schedule' and 'quarry unschedule' CLI commands that manage platform-native timers for periodic background sync across all databases. Single timer iterates 'quarry databases --json' and syncs each. Default hourly interval, configurable. 'quarry install' mentions it but does not auto-enable (explicit opt-in for background CPU).\n\nPlatforms:\n- macOS: launchd agent (~/Library/LaunchAgents/com.quarry.sync.plist)\n- Linux: systemd user timer (~/.config/systemd/user/quarry-sync.timer + .service)\n- Platform detection at runtime; clear error on unsupported platforms\n\nDesign:\n- quarry schedule [--interval 3600] — writes platform-native config, enables timer\n- quarry unschedule — disables timer, removes config\n- quarry schedule --status — shows whether active, last run, next run\n- quarry sync-all — new command: iterates quarry databases --json, syncs each\n- Logging: quarry.log via existing configure_logging\n- quarry doctor: report schedule status (active/inactive, interval)\n- quarry install: print suggestion to run 'quarry schedule' but do not auto-enable\n\nImplementation:\n1. Add 'quarry sync-all' command to __main__.py\n2. Add schedule.py module with platform backends:\n   - LaunchdBackend: plist generation, launchctl bootstrap/bootout\n   - SystemdBackend: unit file generation, systemctl --user enable/disable\n   - Backend protocol for testability\n3. Add 'quarry schedule', 'quarry unschedule' commands to __main__.py\n4. Update quarry doctor to show schedule status\n5. Update quarry install to mention scheduling\n6. Tests for config generation (both platforms), sync-all iteration\n7. Update README with scheduling section","status":"open","priority":2,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-15T16:33:10.214258-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-15T16:34:05.061077-08:00"}
{"id":"quarry-uc2","title":"Add PostToolUse output suppression hook for Claude Code","description":"Add PostToolUse output suppression hook for Claude Code integration.\n\nAdopts org standard punt-kit-bjb. See punt-kit for the standard definition.","status":"closed","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-17T08:36:18.618588-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-24T02:27:43.969497-08:00","closed_at":"2026-02-24T02:27:43.969497-08:00","close_reason":"Completed as part of quarry-h9k (PR #58)"}
{"id":"quarry-v2y","title":"format: RTF ingestion","description":"Ingest RTF files. Library: striprtf. Low priority — rare format in practice. Simple text extraction into existing pipeline.","status":"open","priority":4,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-09T05:36:29.958964-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.006295-08:00"}
{"id":"quarry-vx9","title":"format: CSV ingestion","description":"Ingest CSV files. Configurable chunking: row groups with header repeated per chunk. Stdlib csv module. Design choice: chunk size by row count or byte size.","status":"closed","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-09T05:36:29.838771-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T08:17:49.979621-08:00","closed_at":"2026-02-11T08:17:49.979621-08:00","close_reason":"Folded into quarry-91r (XLSX/XLS/CSV spreadsheet ingestion). Same processor, same LaTeX tabular serialization."}
{"id":"quarry-wul","title":"Rename PyPI package from quarry-mcp to quarry","description":"DESIGN-GUIDANCE.md now requires that dual CLI+MCP projects use the plain name on PyPI, not a -mcp suffix. Quarry is a CLI, MCP server, and has a .mcpb bundle. Rename the PyPI package from quarry-mcp to quarry. Update pyproject.toml [project] name, install instructions in README, PROJECTS.md, and .mcpb manifest references. Check PyPI for name availability first.","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-17T09:39:46.325109-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-19T17:22:46.334929-08:00","closed_at":"2026-02-19T17:22:46.334929-08:00","close_reason":"PyPI package renamed to punt-quarry (PR #50 merged). Bead originally said 'quarry' but punt- prefix convention was adopted org-wide via punt-kit-fbq."}
{"id":"quarry-wzu","title":"feat: MenuBarExtra app shell with status bar icon","status":"closed","priority":1,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-13T17:03:50.976853-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-13T18:04:53.591978-08:00","closed_at":"2026-02-13T18:04:53.591978-08:00","close_reason":"Closed","dependencies":[{"issue_id":"quarry-wzu","depends_on_id":"quarry-kou","type":"blocks","created_at":"2026-02-13T17:03:59.203019-08:00","created_by":"\"jmf-pobox\""},{"issue_id":"quarry-wzu","depends_on_id":"quarry-3fx","type":"blocks","created_at":"2026-02-13T17:03:59.313509-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-xjq","title":"Reconsider MCP tool names for clarity","description":"The MCP tool names shown to users are verbose and confusing. Example: `plugin:quarry:quarry - search_documents` has triple-quarry redundancy. Consider renaming tools for better UX — shorter names, clearer verbs, less namespace noise. Review all tool names in mcp_server.py and manifest.json.","status":"open","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-24T10:41:04.150095-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-24T10:41:09.243484-08:00"}
{"id":"quarry-z3b","title":"pipeline: Handle MPO (Multi-Picture Object) JPEG format","description":"40 files failed with 'Unsupported image format: MPO'. These are iPhone JPEG files with MPO container (multi-shot). Pillow identifies them as MPO not JPEG. Fix: extract the primary JPEG frame from MPO files before OCR, similar to how BMP/WebP are already converted to PNG.","status":"closed","priority":2,"issue_type":"bug","owner":"jmf@pobox.com","created_at":"2026-02-09T07:56:07.309105-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.999666-08:00","closed_at":"2026-02-09T11:56:14.522397-08:00","close_reason":"Fixed in PR #5. MPO recognized, converted to JPEG with EXIF orientation preserved."}
{"id":"quarry-zl4","title":"Add docs CI (markdownlint) to all repos missing it","description":"5 repos lack docs.yml workflow: biff, quarry, langlearn-tts, koch-trainer-swift, quarry-menubar. Need: (1) .markdownlint.jsonc config per repo, (2) .markdownlint-cli2.jsonc to exclude .claude/, .beads/, .venv/, (3) docs.yml workflow, (4) update rulesets to require docs check. Significant markdown debt exists — MD024 (duplicate headings in CHANGELOGs/ADRs), MD040 (unlabeled code blocks), MD032/MD022 (formatting). Strategy: exclude generated content, disable rules that conflict with standard patterns (CHANGELOG, ADR), fix remaining lint errors, add workflow + ruleset.","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-19T21:38:14.302174-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-19T21:38:20.867325-08:00","closed_at":"2026-02-19T21:38:20.867325-08:00","close_reason":"Created in wrong repo, recreating in punt-kit"}
