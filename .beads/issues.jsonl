{"id":"quarry-1fi","title":"tool: Epic 6 — Multi-index management","description":"First-class support for organizing documents into collections.\n\n- Named indices with isolated storage\n- Per-index configuration (embedding model, chunk size)\n- Cross-index search\n- Index metadata and statistics","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T09:19:18.015614-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.002039-08:00","closed_at":"2026-02-08T18:45:07.315467-08:00","close_reason":"Epic 6 complete: collections support across model, database, pipeline, MCP, and CLI. 8 commits, 198 tests."}
{"id":"quarry-1ke","title":"transform: Local OCR backend (RapidOCR)","description":"Make the OCR backend pluggable so quarry can run without AWS credentials.\n\n## Motivation\n- Eliminates AWS dependency and per-page cost ($1.50/1000 pages)\n- Enables offline use\n- Simpler setup (no IAM, S3 bucket, or credentials needed)\n\n## Approach\n- Define an OcrBackend protocol with two operations: sync single-page OCR and async multi-page OCR\n- Implement TextractBackend (existing code in ocr_client.py)\n- Implement LocalBackend wrapping a local engine (PaddleOCR, EasyOCR, or Tesseract)\n- Add OCR_BACKEND setting (default: \"textract\", alternative: \"local\")\n- Pipeline calls backend through protocol, no other changes needed\n\n## Candidates\n- PaddleOCR: best accuracy, ~100MB models, CPU or GPU\n- EasyOCR: good accuracy, PyTorch-based, ~200MB models\n- Tesseract: simplest install, weakest accuracy on noisy/skewed scans\n\n## Open Questions\n- Which local engine? PaddleOCR has best benchmarks but adds PaddlePaddle dependency\n- Should local be an optional extra (quarry-mcp[local])?\n- Acceptable accuracy threshold for handwritten/skewed documents?","status":"closed","priority":0,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-09T05:00:53.494075-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T18:50:10.243054-08:00","closed_at":"2026-02-11T18:50:10.243054-08:00","close_reason":"Implemented LocalOcrBackend using RapidOCR (pure Python, ONNX Runtime). Default changed from textract to local. 6 commits on feat/local-ocr branch."}
{"id":"quarry-2j7","title":"pipeline: Downscale oversized images before OCR","status":"closed","priority":2,"issue_type":"bug","owner":"jmf@pobox.com","created_at":"2026-02-09T16:12:08.456359-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.998916-08:00","closed_at":"2026-02-09T17:16:37.264251-08:00","close_reason":"PR #7 merged: oversized images downscaled before OCR, 13 failures resolved"}
{"id":"quarry-42y","title":"format: HTML ingestion","description":"Ingest saved HTML files. Strip boilerplate/nav/scripts, extract article content. Library: beautifulsoup4. Straightforward text extraction.","status":"open","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-09T05:36:29.715704-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.000157-08:00"}
{"id":"quarry-4ry","title":"pipeline: Fix f-string log formatting","description":"pipeline.py has 11 progress() calls using f-strings that pass through _make_progress() to logger.info(message). This defeats lazy evaluation. Refactor _make_progress to accept format string + args, or convert callers to use %s-style formatting. See NON-FUNCTIONAL-DESIGN.md logging format standard.","status":"closed","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T12:11:59.136548-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.005077-08:00","closed_at":"2026-02-08T12:30:15.66313-08:00","close_reason":"Closed"}
{"id":"quarry-4xq","title":"tool: Hybrid document-level search","description":"Add document-level search combining sparse (keyword) and dense (vector) retrieval to support exhaustive queries like 'how much did I spend on maintenance' where top-N chunk similarity is the wrong tool.\n\n## Problem\n\nCurrent search returns top-N chunks by vector similarity. Works for conceptual queries but fails for exhaustive queries that need ALL matching documents regardless of similarity rank. Document names are unreliable (e.g. scan.pdf, IMG_5349.jpg) so metadata filtering by name is insufficient.\n\n## Design\n\n### Document metadata table\n\nAt ingestion time, after chunking and embedding, generate and store per-document:\n- Document-level embedding: np.mean(chunk_vectors, axis=0) — already computed, just store the mean\n- Keywords: TF-IDF or statistical extraction from page text — zero additional API cost\n- Store in a separate document_metadata table in LanceDB\n\n### New MCP tool: find_documents\n\nHybrid search against the document metadata table:\n- Dense: vector similarity against document-level embedding\n- Sparse: keyword/BM25 matching against extracted terms\n- LanceDB supports both natively (full-text search index + vector index)\n- Returns document-level results (name, collection, pages, keywords) not chunks\n- Small responses — document list only, no chunk text\n\n### Retrieval flow for exhaustive queries\n\n1. find_documents(collection='hallberg-rassy', query='invoice') → complete document list (small response)\n2. get_page(doc, page) for each document → extract specific data\n3. LLM aggregates the answers\n\n### Retrieval flow for conceptual queries\n\nsearch_documents (existing) — unchanged, top-N chunk similarity\n\n## Cost\n\nZero additional API calls. Keywords extracted from existing text. Document embedding is mean of existing chunk vectors. Both computed at end of _chunk_embed_store.","status":"open","priority":2,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-10T05:44:54.181898-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T08:42:52.276075-08:00"}
{"id":"quarry-53v","title":"infra: Add page_type and source_format columns to LanceDB schema","description":"Add two new string columns to the LanceDB chunk schema and populate them during ingestion for all existing formats.\n\n## Schema changes\n- `page_type` (pa.utf8()) — content type: text, code, spreadsheet, presentation, email\n- `source_format` (pa.utf8()) — file extension: .pdf, .py, .xlsx, etc.\n\n## Pipeline changes\n- Pass page_type through from PageContent to Chunk to LanceDB record\n- Add source_format (derived from file extension) at ingest time\n- Update all existing ingest functions: ingest_pdf, ingest_text_file, ingest_image, ingest_code_file\n\n## PageType redefinition\n- PDF pages: both TEXT and IMAGE extraction produce page_type=\"text\" in stored chunks\n- SECTION → \"text\" (MD, TXT, DOCX, TEX are all prose)\n- CODE stays \"code\"\n- The PageType enum in models.py may need updating or the mapping happens at storage time\n\n## Breaking change\nExisting indexes need re-ingestion (quarry sync) to populate new columns. Acceptable — no production users yet.","status":"open","priority":1,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-11T06:57:51.296526-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:57:51.296526-08:00"}
{"id":"quarry-62k","title":"pipeline: Epic 8 — Ingestion performance","description":"Scalable ingestion for 1000s of documents. Content hashing for skip-if-unchanged, directory registration with incremental re-indexing, parallel multi-document ingestion, exponential backoff for Textract polling. Depends on Epic 6 (complete).","status":"closed","priority":1,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-08T19:41:16.158214-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.996893-08:00","closed_at":"2026-02-09T04:50:06.993624-08:00","close_reason":"Merged PR #1: directory registration, incremental sync, exponential backoff, CLI/MCP tools. 245 unit + 21 integration tests."}
{"id":"quarry-65r","title":"infra: Rename beads prefix from ocr- to quarry-","description":"The beads issue prefix is still 'ocr-' from the original project name. Investigate whether beads supports renaming the prefix, and if so, migrate all existing issues to use 'quarry-' prefix.","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-10T04:58:36.866565-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:35.362258-08:00","closed_at":"2026-02-11T06:24:35.362258-08:00","close_reason":"Renamed 44 issues from ocr- to quarry- prefix"}
{"id":"quarry-66p","title":"infra: Epic 7 — Package distribution and CLI","description":"Turn quarry-mcp into a proper installable Python package with setup/diagnostic CLI commands.\n\n## Package Distribution\n- Publish to PyPI (or at minimum, installable via `pip install .` / `uv pip install .`)\n- Entry point script so `quarry` command works after install (no `uv run python -m quarry`)\n- Clean dependency specification in pyproject.toml (separate core vs optional deps)\n\n## CLI Commands\n- `quarry install`: First-run setup — download embedding model, create data directory, verify AWS credentials, configure MCP server registration\n- `quarry doctor`: Diagnostic command — check Python version, verify dependencies installed, test AWS connectivity, verify embedding model cached, check LanceDB path writable, report MCP server status","status":"closed","priority":2,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-08T13:43:59.64367-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.001275-08:00","closed_at":"2026-02-08T13:59:31.50876-08:00","close_reason":"Implemented: version management, data path fix, doctor command, install command"}
{"id":"quarry-77n","title":"pipeline: Skip macOS resource fork files and .Trash during sync","description":"Sync walker picks up macOS ._* resource fork files and .Trash directories. These cause 'Failed to open file' errors (14 files) and Textract InvalidParameter errors (9 files from .Trash PNGs). Fix: skip files matching ._* prefix and .Trash directories in the directory walker.","status":"closed","priority":1,"issue_type":"bug","owner":"jmf@pobox.com","created_at":"2026-02-09T07:56:04.312826-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.996065-08:00","closed_at":"2026-02-09T08:24:45.831592-08:00","close_reason":"Fixed in PR #4. discover_files now skips dotfiles, resource forks, and hidden directories."}
{"id":"quarry-7pv","title":"tool: Optimize MCP response sizes","description":"Large MCP responses (~12.5k tokens) observed filling context quickly.\n\n## Root cause\n\nExhaustive queries forced through top-N chunk search — addressed by ocr-4xq (hybrid document-level search).\n\n## Residual optimization for search_documents\n\nEven for conceptual queries, chunk-level search responses are larger than necessary:\n- Truncate text field in results (e.g. 200 chars with ellipsis) — callers can use get_page for full text\n- Drop chunk_index from results (rarely useful to callers)\n- Consider default limit=5 instead of 10\n- Consider a brief=true flag for compact responses\n\nThese are independent of ocr-4xq and worth doing regardless.","status":"open","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-10T04:56:16.965539-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T08:42:52.377094-08:00","dependencies":[{"issue_id":"quarry-7pv","depends_on_id":"quarry-4xq","type":"blocks","created_at":"2026-02-10T05:52:33.02074-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-7ua","title":"infra: Rename beads prefix (duplicate)","description":"Beads issues use ocr- prefix from the original project name. Project is now quarry-mcp. Rename prefix to quarry- for consistency. Check if bd supports prefix migration or if issues need manual recreation.","status":"closed","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-09T07:17:57.450816-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.003317-08:00","closed_at":"2026-02-10T05:02:01.078932-08:00","close_reason":"Duplicate of ocr-65r"}
{"id":"quarry-8nu","title":"tool: Sitemap crawling for bulk URL ingestion","description":"Parse sitemap.xml to discover URLs, then batch-ingest each page using URL ingestion. Supports documentation sites, blogs, reference manuals. Depends on URL ingestion feature. Add as MCP tool (ingest_sitemap) and CLI command.","status":"open","priority":4,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-09T11:43:00.146025-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.00579-08:00","dependencies":[{"issue_id":"quarry-8nu","depends_on_id":"quarry-pcr","type":"blocks","created_at":"2026-02-09T11:43:08.895941-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-8si","title":"epic: Search-by-format — persist content type and source format in chunks","description":"Enable end users to filter semantic searches by document format (e.g. \"find spreadsheets with DCF models\"). Requires coordinated changes across schema, ingestion pipeline, and search.\n\n## Design Decisions (settled)\n\n### PageType redefined as content type (Option A)\nPageType becomes a **content type** classification, not an extraction method. The TEXT/IMAGE distinction for PDF pages (which described extraction routing) is dropped from stored metadata. After extraction, all prose chunks are the same regardless of whether they came from PyMuPDF or Textract.\n\nStored PageType values:\n- `text` — prose documents (PDF, MD, TXT, DOCX, TEX, OCR results)\n- `code` — source code (tree-sitter split)\n- `spreadsheet` — tabular data (XLSX, CSV)\n- `presentation` — slides (PPTX)\n- `email` — structured messages (EML/MBOX, future)\n\nThe PDF analyzer still uses TEXT/IMAGE internally for pipeline routing; that classification does not propagate to chunks.\n\n### Two new chunk schema columns\n1. **`page_type`** (string) — content type from the enum above. Coarse filter: \"show me only spreadsheets.\"\n2. **`source_format`** (string) — file extension (`.pdf`, `.py`, `.xlsx`). Precise filter: \"show me only Excel files.\"\n\nBoth stored as LanceDB columns, filterable via SQL WHERE clauses in search.\n\n### XLSX stored as LaTeX tabular\nSpreadsheet content is serialized as LaTeX `\\begin{tabular}` via `pandas.DataFrame.to_latex()`. This reuses the existing LaTeX-aware text_processor for chunking, and LLMs parse LaTeX tables natively.\n\n### Search API\n`search_documents` gains optional `page_type` and `source_format` filter parameters, implemented as LanceDB WHERE clauses.\n\n## Constituent work\n- Schema: add `page_type` and `source_format` columns to LanceDB schema\n- Pipeline: persist both fields during ingestion for all existing formats\n- XLSX ingestion: new spreadsheet_processor using pandas + openpyxl, LaTeX output\n- Search: expose filter parameters in MCP tool and CLI\n- Backfill: existing indexed documents need re-ingestion (quarry sync) to populate new columns","status":"open","priority":1,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-11T06:57:13.533993-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:57:13.533993-08:00","dependencies":[{"issue_id":"quarry-8si","depends_on_id":"quarry-53v","type":"blocks","created_at":"2026-02-11T08:17:29.207735-08:00","created_by":"\"jmf-pobox\""},{"issue_id":"quarry-8si","depends_on_id":"quarry-mo5","type":"blocks","created_at":"2026-02-11T08:17:29.335745-08:00","created_by":"\"jmf-pobox\""},{"issue_id":"quarry-8si","depends_on_id":"quarry-91r","type":"blocks","created_at":"2026-02-11T08:17:29.4734-08:00","created_by":"\"jmf-pobox\""},{"issue_id":"quarry-8si","depends_on_id":"quarry-ebv","type":"blocks","created_at":"2026-02-11T08:17:29.616355-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-91r","title":"format: XLSX/XLS spreadsheet ingestion","description":"Ingest Excel spreadsheets into quarry.\n\n## Design Decisions (settled)\n\n### Serialization: LaTeX tabular\nSpreadsheet content is serialized as LaTeX `\\begin{tabular}` via `pandas.DataFrame.to_latex()`. This reuses the existing LaTeX-aware text_processor for chunking, and LLMs parse LaTeX tables natively. Same approach applies to CSV.\n\n### Chunking strategy\nOne LaTeX tabular block per sheet. Large sheets (\u003e1800 chars after LaTeX conversion) get split by row groups with column headers repeated in each chunk.\n\n### Libraries\n- `pandas` — already a transitive dependency of sentence-transformers (free)\n- `openpyxl` — XLSX backend for pandas (~4 MB, new explicit dependency)\n\n### PageType\nChunks get `page_type=\"spreadsheet\"` and `source_format=\".xlsx\"` (or `.csv`, `.xls`).\n\n### Scope\n- New `spreadsheet_processor.py` module\n- Add `.xlsx`, `.xls`, `.csv` to SUPPORTED_EXTENSIONS\n- Serialize via pandas to_latex(), feed into text_processor for chunking\n- Persist page_type and source_format in chunks\n- Handle: multiple sheets (chunk per sheet), merged cells (flatten), formulas (value only)\n- Depends on schema columns existing (quarry-8si epic)","status":"open","priority":1,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-09T05:35:40.729921-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:57:32.555491-08:00","dependencies":[{"issue_id":"quarry-91r","depends_on_id":"quarry-53v","type":"blocks","created_at":"2026-02-11T06:57:57.228366-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-a9v","title":"infra: Backend abstraction Phase 1 — Protocols and factory","description":"Extract OcrBackend and EmbeddingBackend protocols from existing code. Wrap current functions in backend classes. Create factory with caching.\n\n## Scope (from docs/BACKEND-ABSTRACTION.md Phase 1)\n\n1. Add OcrBackend and EmbeddingBackend protocols to types.py\n2. Add TextractOcrBackend class to ocr_client.py (wraps ocr_document_via_s3, ocr_image_bytes)\n3. Add SnowflakeEmbeddingBackend class to embeddings.py (wraps embed_texts, embed_query, owns model cache)\n4. Create backends.py with get_ocr_backend() and get_embedding_backend() factory functions\n5. Add ocr_backend setting to config.py\n6. Tests for new classes and factory\n\n## Files\n\n- src/quarry/types.py — MODIFY (add 2 protocols)\n- src/quarry/ocr_client.py — MODIFY (add TextractOcrBackend class)\n- src/quarry/embeddings.py — MODIFY (add SnowflakeEmbeddingBackend class)\n- src/quarry/backends.py — NEW (~40 lines)\n- src/quarry/config.py — MODIFY (add ocr_backend field)\n- tests/test_backends.py — NEW\n\n## Does NOT include\n\n- Pipeline wiring (Phase 2)\n- MCP/CLI call-site changes (Phase 2)\n- Audio transcription protocol (Phase 3)\n- Local OCR implementation (Phase 4)","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-09T05:30:41.904627-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.000732-08:00","closed_at":"2026-02-09T06:14:17.766994-08:00","close_reason":"Phase 1 complete: 2 protocols, 2 backend classes, thread-safe factory, 12 tests"}
{"id":"quarry-axj","title":"format: Epic 2 — Text document ingestion","description":"Direct ingestion of text-based formats without OCR.\n\n- Plain text files (.txt)\n- Markdown (.md)\n- LaTeX (.tex)\n- DOCX (via python-docx or similar)\n- Configurable page/section boundary detection\n- String ingestion: ingest raw text/markdown/HTML from clipboard, web pages, or chat context (no file required)","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T09:19:14.846313-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.002538-08:00","closed_at":"2026-02-08T11:11:59.562506-08:00","close_reason":"Text document ingestion implemented: .txt, .md, .tex, .docx files + raw string ingestion via MCP"}
{"id":"quarry-b0j","title":"pipeline: PII detection and redaction","description":"Prevent PII from reaching LLM context windows via ingestion-time detection and retrieval-time redaction. Secure by default (on by default, opt-out).\n\n## Threat Model\n\nUsers unknowingly send PII to LLMs through MCP responses. quarry stores invoices, contracts, and personal documents containing names, addresses, emails, phone numbers, and financial account numbers.\n\n## Design\n\n### Ingestion-time detection\n- After chunking, run Microsoft Presidio analyzer on each chunk's text\n- Store detected PII spans as metadata: entity type, start offset, end offset\n- Store as JSON column (pii_spans) on each chunk row in LanceDB\n- Also detect on page_raw_text separately (different offsets than chunk text)\n- Embeddings computed on full unredacted text — preserves search quality\n\n### Retrieval-time redaction\n- Before returning MCP responses, apply stored spans to replace PII with placeholders\n- Placeholder style: [PERSON], [EMAIL], [PHONE], [ADDRESS], etc. (Presidio standard)\n- Applies to both search_documents results and get_page responses\n- Toggle: pii_redaction setting in Settings, True by default\n\n### Audit tool\n- New MCP tool: find documents/chunks containing specific PII entity types\n- Query stored pii_spans metadata across all chunks\n- Example: 'which documents contain PHONE_NUMBER entities'\n\n## Schema Addition\n\nNew column on chunks table:\n  pii_spans: utf8 (JSON string)\n  pii_spans_raw: utf8 (JSON string, for page_raw_text)\n\nExample value:\n  [{\"type\": \"PERSON\", \"start\": 42, \"end\": 55}, {\"type\": \"EMAIL\", \"start\": 120, \"end\": 148}]\n\n## Dependencies\n\n- Microsoft Presidio as optional dependency: quarry[pii] extra\n- Presidio wraps spaCy + regex recognizers, runs locally, no API cost\n- PII entity types: PERSON, EMAIL_ADDRESS, PHONE_NUMBER, LOCATION/ADDRESS, CREDIT_CARD, US_SSN, IBAN, and others from Presidio defaults\n\n## Configuration\n\n- pii_redaction: bool = True (secure by default)\n- pii_entity_types: list of entity types to detect (default: all Presidio defaults)\n- Per-collection config deferred\n\n## Commits (rough)\n\n1. Add Presidio as optional dependency, pii_redaction setting\n2. Add pii_spans/pii_spans_raw columns to LanceDB schema\n3. PII detection module wrapping Presidio analyzer\n4. Integrate detection into _chunk_embed_store pipeline\n5. Retrieval-time redaction in search and get_page MCP responses\n6. Audit MCP tool: query PII spans across chunks\n7. Tests for detection, redaction, and audit","status":"open","priority":2,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-10T06:31:35.378665-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T08:42:52.178377-08:00"}
{"id":"quarry-bez","title":"format: Email ingestion (EML/MBOX)","description":"Ingest email files into quarry.\n\n## Approach\n- stdlib email module parses EML and MBOX formats\n- Extract: subject, from, to, date, body (plain text and/or HTML→text)\n- Recurse into attachments: ingest supported formats (PDF, DOCX, images, etc.) as separate documents\n- One chunk per email message, or split long bodies\n- MBOX files contain multiple messages — each becomes a separate document or chunk\n\n## Scope\n- New parser module or addition to text_processor.py\n- Add .eml, .mbox to SUPPORTED_EXTENSIONS\n- Attachment handling reuses existing ingest_document pipeline\n- No new dependencies (stdlib email, html.parser)\n- No new protocol needed","status":"open","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-09T05:36:21.19669-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.004337-08:00"}
{"id":"quarry-bsj","title":"pipeline: Handle concurrent table creation race condition","description":"First file in sync fails with 'Table ocr_chunks already exists' when multiple workers try to create the table simultaneously. Fix: use create-if-not-exists pattern or catch the error and retry.","status":"closed","priority":2,"issue_type":"bug","owner":"jmf@pobox.com","created_at":"2026-02-09T07:56:11.466845-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.999166-08:00","closed_at":"2026-02-09T17:51:38.691813-08:00","close_reason":"Fixed with double-checked locking in insert_chunks. PR #8."}
{"id":"quarry-bww","title":"infra: Add missing Raises docstring sections","description":"Multiple public functions raise or propagate exceptions but lack Raises: docstring sections. Files: ocr_client.py (ocr_pdf_pages), embeddings.py (embed_texts, embed_query), database.py (get_db, insert_chunks, search, get_page_text, delete_document), text_processor.py (process_text_file — missing FileNotFoundError, UnicodeDecodeError), pdf_analyzer.py (analyze_pdf), text_extractor.py (extract_text_pages). See NON-FUNCTIONAL-DESIGN.md Rule 5.","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T12:11:59.136979-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.001525-08:00","closed_at":"2026-02-08T12:30:15.667497-08:00","close_reason":"Closed"}
{"id":"quarry-cdv","title":"tool: Add status/health tool to MCP server","description":"local-rag exposes a status tool (document count, chunk count, memory usage, search mode). Quarry should expose similar diagnostics.\n\n- Total documents and chunks\n- Database path and size on disk\n- Embedding model name and dimension\n- Uptime or version","status":"closed","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T10:12:58.767725-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.00532-08:00","closed_at":"2026-02-08T10:29:34.964385-08:00","close_reason":"Closed"}
{"id":"quarry-cjs","title":"pipeline: Add exception handling at system boundaries","description":"All 6 MCP tool handlers in mcp_server.py and all 4 CLI commands in __main__.py let raw tracebacks escape to users. Each boundary handler should catch expected exceptions (FileNotFoundError, ValueError, RuntimeError, TimeoutError), log with logger.exception(), and return user-friendly messages. See NON-FUNCTIONAL-DESIGN.md Rule 7.","status":"closed","priority":1,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T12:11:59.13632-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.997441-08:00","closed_at":"2026-02-08T12:21:55.714433-08:00","close_reason":"Closed"}
{"id":"quarry-dcg","title":"format: Source code language-aware ingestion","description":"Source code already works as .txt but chunking is naive. Language-aware splitting by function/class boundaries would produce better semantic chunks. Tree-sitter or simple regex-based splitting. Low priority — code search is a different problem space.","status":"closed","priority":4,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-09T05:36:30.07829-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.006051-08:00","closed_at":"2026-02-10T12:33:30.133948-08:00","close_reason":"Merged PR #10, released v0.3.0. Tree-sitter required dependency, 30+ languages, 20 tests."}
{"id":"quarry-ebv","title":"format: PPTX/PPT presentation ingestion","description":"Ingest PowerPoint presentations into quarry.\n\n## Design Decisions (settled)\n\n### Chunking strategy\nOne slide = one chunk. Slide title + body text + speaker notes concatenated. Natural boundary that matches how presentations are structured.\n\n### PageType\nChunks get `page_type=\"presentation\"` and `source_format=\".pptx\"`.\n\n### Tables in slides\nTables within slides serialized as LaTeX tabular (same approach as XLSX). Consistent representation for all tabular data regardless of source.\n\n### Embedded images\nPhase 1: skip. Phase 2: OCR via OcrBackend (depends on image extraction from PPTX).\n\n### Library\npython-pptx (already in dev environment, needs to become a dependency).\n\n### Scope\n- New `presentation_processor.py` module\n- Add `.pptx` to SUPPORTED_EXTENSIONS\n- Feed parsed text into existing chunk-embed-store pipeline\n- Persist page_type and source_format in chunks\n- Depends on schema columns existing (quarry-8si epic)","status":"open","priority":2,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-09T05:36:14.380605-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T08:42:52.475559-08:00","dependencies":[{"issue_id":"quarry-ebv","depends_on_id":"quarry-53v","type":"blocks","created_at":"2026-02-11T06:57:57.345303-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-ekd","title":"pipeline: Fix resource leaks in fitz.open","description":"pdf_analyzer.py:14 and text_extractor.py:25 open fitz.open() without try/finally. If an exception occurs during page iteration, the PDF handle leaks. Wrap in try/finally with doc.close() in the finally block. See NON-FUNCTIONAL-DESIGN.md Rule 6.","status":"closed","priority":1,"issue_type":"bug","owner":"jmf@pobox.com","created_at":"2026-02-08T12:11:59.143001-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.997179-08:00","closed_at":"2026-02-08T12:21:55.712416-08:00","close_reason":"Closed"}
{"id":"quarry-ewr","title":"connector: Google Drive integration","description":"Native Google Drive API integration for registering and syncing Google Drive folders as collections. Authenticate via OAuth2 or service account. Download files to temp storage, ingest, track sync state in registry. Supports Docs, Sheets, Slides (export as DOCX/XLSX/PPTX). Note: Google Drive for Desktop mounts work today with quarry register as a workaround.","status":"open","priority":4,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-09T11:43:04.971154-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T08:32:15.549192-08:00"}
{"id":"quarry-jlo","title":"format: Epic 3 — Image format support","description":"OCR for standalone image files (not wrapped in PDF).\n\n- Common formats: PNG, JPG, TIFF, BMP, WebP\n- Single-image and batch ingestion\n- Image preprocessing for OCR quality (deskew, contrast)","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T09:19:15.290644-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.002289-08:00","closed_at":"2026-02-08T12:55:01.240407-08:00","close_reason":"Closed"}
{"id":"quarry-k7h","title":"tool: Expose delete_document via MCP and CLI","description":"The database layer has delete_document() but it is not exposed through the MCP server or CLI. local-rag exposes delete_file — quarry should too.\n\n- Add delete_document tool to MCP server\n- Add 'quarry delete \u003cdocument_name\u003e' CLI command\n- Confirm deletion returns feedback (e.g. chunk count removed)","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T10:12:56.56393-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.001788-08:00","closed_at":"2026-02-08T10:29:34.962562-08:00","close_reason":"Closed"}
{"id":"quarry-kfb","title":"pipeline: Epic 5 — Ingestion quality","description":"Post-processing to improve extracted text quality.\n\n- LLM-based OCR error correction\n- Chunk quality scoring and filtering\n- Duplicate and near-duplicate detection\n- Table and figure extraction","status":"closed","priority":1,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T09:19:17.214071-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.997693-08:00","closed_at":"2026-02-10T05:04:26.110793-08:00","close_reason":"Scope too vague — four unrelated projects bundled together. Duplicate detection is the only tractable item; can be re-created as a standalone task if needed."}
{"id":"quarry-kog","title":"format: EPUB ingestion","description":"Ingest EPUB ebooks. HTML chapters, strip tags, section-aware splitting. Library: ebooklib. Straightforward — same pipeline as DOCX.","status":"open","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-09T05:36:29.596769-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.00409-08:00"}
{"id":"quarry-l5s","title":"infra: Add DEBUG logging to database queries","description":"database.py search() and get_page_text() lack DEBUG logging. Add logger.debug for query parameters (limit, document_filter) and result counts. See NON-FUNCTIONAL-DESIGN.md DEBUG-level standard.","status":"closed","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T12:11:59.139247-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.004834-08:00","closed_at":"2026-02-08T12:30:15.666118-08:00","close_reason":"Closed"}
{"id":"quarry-lh5","title":"transform: Audio transcription backend","description":"Speech-to-text ingestion for audio content.\n\n- Audio format support: MP3, WAV, M4A, FLAC\n- AWS Transcribe or Whisper integration\n- Speaker diarization\n- Timestamped chunks for source reference","status":"open","priority":4,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T09:19:16.247327-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T08:43:01.690996-08:00"}
{"id":"quarry-lpd","title":"infra: Rename ocr_chunks table to chunks","description":"The LanceDB table is still named 'ocr_chunks' (TABLE_NAME in database.py) but the project was renamed to quarry. Rename the table constant and update all references. Consider: migration path for existing databases with data in the old table name.","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-10T04:58:07.026992-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.998656-08:00","closed_at":"2026-02-10T05:57:37.689673-08:00","close_reason":"PR #9 — renamed TABLE_NAME from ocr_chunks to chunks"}
{"id":"quarry-m70","title":"infra: Backend abstraction Phase 2 — Pipeline wiring","description":"Replace direct function calls with factory calls. All call sites go through get_ocr_backend() and get_embedding_backend().\n\n## Scope (from docs/BACKEND-ABSTRACTION.md Phase 2)\n\n1. pipeline.py — replace ocr_document_via_s3() and embed_texts() calls with factory calls\n2. mcp_server.py — replace 2 embed_query() calls with get_embedding_backend(settings).embed_query()\n3. __main__.py — replace 1 embed_query() call with get_embedding_backend(settings).embed_query()\n4. Update test mocking (patch factory instead of module functions)\n\n## Files\n\n- src/quarry/pipeline.py — MODIFY\n- src/quarry/mcp_server.py — MODIFY\n- src/quarry/__main__.py — MODIFY\n- tests/test_pipeline.py — MODIFY (mock factory)\n- tests/test_pipeline_images.py — MODIFY (mock factory)\n- tests/test_mcp_server.py — MODIFY (mock factory)\n- tests/test_cli.py — MODIFY (mock factory)\n\n## Depends on\n\nPhase 1 (ocr-a9v): protocols, implementations, factory must exist first.","status":"closed","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-09T05:32:03.207114-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.000413-08:00","closed_at":"2026-02-09T06:22:21.351143-08:00","close_reason":"Pipeline, CLI, and MCP server now use backend factory. All 257 unit tests pass.","dependencies":[{"issue_id":"quarry-m70","depends_on_id":"quarry-a9v","type":"blocks","created_at":"2026-02-09T05:32:05.957727-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-mdj","title":"infra: Add rename/move operation to database layer","description":"When a file is renamed or moved, the stored document_name and document_path in LanceDB become stale. Currently sync treats this as delete + re-ingest, wasting OCR and embedding compute.\n\n## Database layer\n\nAdd rename_document() to database.py that updates document_name and document_path columns via table.update() with a WHERE filter. No re-embedding or re-chunking needed.\n\n## Sync integration\n\nIn compute_sync_plan(), after building to_delete and to_ingest lists, cross-reference them: if a deletion candidate and an ingestion candidate share the same size+mtime, treat it as a rename instead of delete+ingest. mv preserves both attributes on the same filesystem.\n\nSyncPlan gains a to_rename list of (old_record, new_path) tuples. sync_collection handles renames via rename_document() + registry update.\n\nAmbiguous case (multiple files with identical size+mtime): fall back to delete+ingest.\n\n## Three layers to update\n\n1. LanceDB — document_name and document_path columns (rename_document)\n2. SQLite registry — files table row: update path, document_name\n3. Sync engine — rename detection in compute_sync_plan, rename execution in sync_collection","status":"closed","priority":2,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-10T05:00:39.414787-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.998076-08:00","closed_at":"2026-02-10T06:20:24.31693-08:00","close_reason":"Not pursuing rename support — delete+re-ingest is acceptable. Local OCR (ocr-1ke) reduces the cost of re-ingestion, making renames a non-issue."}
{"id":"quarry-mo5","title":"tool: Search metadata filters","description":"Add optional filters to search_documents: page_type (content type) and source_format (file extension).\n\n## Design Decisions (settled)\n\n### Filter parameters\n- `page_type` (string, optional) — coarse content filter. Values: text, code, spreadsheet, presentation, email. Example: `page_type=\"spreadsheet\"` returns only tabular data chunks.\n- `source_format` (string, optional) — precise format filter. Values: file extensions like `.pdf`, `.py`, `.xlsx`. Example: `source_format=\".xlsx\"` returns only Excel-sourced chunks.\n\n### Implementation\nBoth filters become LanceDB SQL WHERE clauses on stored chunk columns. No post-filtering needed.\n\n### Scope\n- Add `page_type` and `source_format` parameters to `search_documents` MCP tool\n- Add `--page-type` and `--source-format` CLI flags to `quarry search`\n- Requires schema columns to exist first (depends on schema work in quarry-8si epic)\n\n## Example use case\nUser searches: \"DCF model\", source_format=\".xlsx\" → returns only spreadsheet chunks containing DCF-related content, excluding PDF slides and markdown docs that mention DCF theory.","status":"open","priority":1,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-09T11:43:01.850212-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:57:22.852993-08:00","dependencies":[{"issue_id":"quarry-mo5","depends_on_id":"quarry-53v","type":"blocks","created_at":"2026-02-11T06:57:57.107014-08:00","created_by":"\"jmf-pobox\""}]}
{"id":"quarry-o9k","title":"infra: Add DEBUG logging to I/O modules","description":"pdf_analyzer.py, text_extractor.py, and text_processor.py do file I/O but have no logger. Add logger = logging.getLogger(__name__) and DEBUG-level logs for: page classification decisions and thresholds (pdf_analyzer), extraction operations (text_extractor), format detection and section split counts (text_processor). See NON-FUNCTIONAL-DESIGN.md.","status":"closed","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-08T12:11:59.141752-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.004581-08:00","closed_at":"2026-02-08T12:30:15.664803-08:00","close_reason":"Closed"}
{"id":"quarry-osk","title":"format: HEIC image ingestion","description":"Add HEIC/HEIF image support. Apple's default camera format — 156 files in the boating library alone. macOS sips can convert to JPEG; Pillow with pillow-heif can handle cross-platform. Needs pipeline recognition of .heic/.heif extensions and conversion to a Textract-supported format (JPEG/PNG) before OCR.","status":"open","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-09T07:14:42.241905-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.003572-08:00"}
{"id":"quarry-pcr","title":"format: URL webpage ingestion","description":"Fetch a URL, extract text from HTML, and ingest as a document. Leverage existing text pipeline (ingest_text). Add as MCP tool (ingest_url) and CLI command. Use requests + beautifulsoup4 or similar for HTML-to-text extraction.","status":"open","priority":3,"issue_type":"feature","owner":"jmf@pobox.com","created_at":"2026-02-09T11:42:58.002882-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.003043-08:00"}
{"id":"quarry-q3r","title":"infra: Schema migration strategy for LanceDB","description":"When the LanceDB schema changes (new columns, type changes), existing databases break with 'No field named X' errors. Need a migration strategy: detect schema version, add missing columns with defaults, or provide a quarry migrate CLI command. Discovered during first real-world sync — old schema lacked 'collection' column.","status":"open","priority":2,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-09T07:16:06.985363-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.999917-08:00"}
{"id":"quarry-r87","title":"pipeline: Handle non-UTF-8 text file encodings","description":"5 German text files failed with 'utf-8 codec can't decode byte'. These are Latin-1/CP1252 encoded. Fix: detect encoding (chardet or charset-normalizer) and decode accordingly, or fall back to latin-1 when utf-8 fails.","status":"closed","priority":2,"issue_type":"bug","owner":"jmf@pobox.com","created_at":"2026-02-09T07:56:09.555844-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.999417-08:00","closed_at":"2026-02-09T14:06:01.981067-08:00","close_reason":"Fixed in PR #6. UTF-8 → CP1252 → Latin-1 fallback chain."}
{"id":"quarry-v2y","title":"format: RTF ingestion","description":"Ingest RTF files. Library: striprtf. Low priority — rare format in practice. Simple text extraction into existing pipeline.","status":"open","priority":4,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-09T05:36:29.958964-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:26.006295-08:00"}
{"id":"quarry-vx9","title":"format: CSV ingestion","description":"Ingest CSV files. Configurable chunking: row groups with header repeated per chunk. Stdlib csv module. Design choice: chunk size by row count or byte size.","status":"closed","priority":3,"issue_type":"task","owner":"jmf@pobox.com","created_at":"2026-02-09T05:36:29.838771-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T08:17:49.979621-08:00","closed_at":"2026-02-11T08:17:49.979621-08:00","close_reason":"Folded into quarry-91r (XLSX/XLS/CSV spreadsheet ingestion). Same processor, same LaTeX tabular serialization."}
{"id":"quarry-z3b","title":"pipeline: Handle MPO (Multi-Picture Object) JPEG format","description":"40 files failed with 'Unsupported image format: MPO'. These are iPhone JPEG files with MPO container (multi-shot). Pillow identifies them as MPO not JPEG. Fix: extract the primary JPEG frame from MPO files before OCR, similar to how BMP/WebP are already converted to PNG.","status":"closed","priority":2,"issue_type":"bug","owner":"jmf@pobox.com","created_at":"2026-02-09T07:56:07.309105-08:00","created_by":"\"jmf-pobox\"","updated_at":"2026-02-11T06:24:25.999666-08:00","closed_at":"2026-02-09T11:56:14.522397-08:00","close_reason":"Fixed in PR #5. MPO recognized, converted to JPEG with EXIF orientation preserved."}
