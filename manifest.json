{
  "manifest_version": "0.4",
  "name": "quarry",
  "display_name": "Quarry",
  "version": "0.7.0",
  "description": "Search your documents by meaning. Index PDFs, images, spreadsheets, presentations, code, and webpages — then ask Claude about them.",
  "long_description": "Quarry extracts knowledge from your files and makes it searchable by meaning. It reads PDFs (text and scanned), images, spreadsheets, presentations, source code, Markdown, LaTeX, DOCX, HTML, and webpages.\n\nEverything runs locally — no cloud accounts or API keys required. The embedding model (~500 MB) downloads automatically on first use.\n\nOnce installed, ask Claude to index a file or search your knowledge base. Quarry handles the rest.",
  "author": {
    "name": "JF",
    "email": "jmf@pobox.com",
    "url": "https://github.com/punt-labs"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/punt-labs/quarry.git"
  },
  "homepage": "https://github.com/punt-labs/quarry",
  "documentation": "https://github.com/punt-labs/quarry#readme",
  "support": "https://github.com/punt-labs/quarry/issues",
  "server": {
    "type": "uv",
    "entry_point": "src/quarry/mcp_server.py",
    "mcp_config": {
      "command": "uv",
      "args": ["run", "--directory", "${__dirname}", "quarry", "mcp"],
      "env": {
        "QUARRY_ROOT": "${user_config.data_directory}"
      }
    }
  },
  "user_config": {
    "data_directory": {
      "type": "directory",
      "title": "Data Directory",
      "description": "Where Quarry stores databases, indexes, and logs",
      "default": "${HOME}/.quarry/data",
      "required": true
    }
  },
  "tools": [
    {
      "name": "search_documents",
      "description": "Search indexed documents using semantic similarity"
    },
    {
      "name": "ingest_file",
      "description": "Index a file by path (PDF, image, spreadsheet, code, etc.)"
    },
    {
      "name": "ingest_url",
      "description": "Fetch and index a webpage"
    },
    {
      "name": "ingest_sitemap",
      "description": "Crawl a sitemap and ingest all discovered URLs"
    },
    {
      "name": "ingest_content",
      "description": "Index inline text (for uploads, clipboard, etc.)"
    },
    {
      "name": "get_documents",
      "description": "List all indexed documents with metadata"
    },
    {
      "name": "get_page",
      "description": "Get raw text for a specific document page"
    },
    {
      "name": "delete_document",
      "description": "Delete all indexed data for a document"
    },
    {
      "name": "list_collections",
      "description": "List all collections with document and chunk counts"
    },
    {
      "name": "delete_collection",
      "description": "Delete all indexed data for a collection"
    },
    {
      "name": "register_directory",
      "description": "Register a directory for incremental sync"
    },
    {
      "name": "deregister_directory",
      "description": "Remove a directory registration"
    },
    {
      "name": "sync_all_registrations",
      "description": "Sync all registered directories: ingest new/changed, remove deleted"
    },
    {
      "name": "list_registrations",
      "description": "List all registered directories"
    },
    {
      "name": "list_databases",
      "description": "List all named databases with document counts and storage size"
    },
    {
      "name": "use_database",
      "description": "Switch to a different named database for subsequent operations"
    },
    {
      "name": "status",
      "description": "Get database status: document/chunk counts, storage size, model info"
    }
  ],
  "privacy_policies": [],
  "compatibility": {
    "platforms": ["darwin", "linux"],
    "runtimes": {
      "python": ">=3.13"
    }
  },
  "keywords": ["search", "documents", "ocr", "vector-search", "knowledge-base", "semantic-search"],
  "license": "MIT"
}
